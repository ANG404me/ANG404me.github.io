<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0"><title>【SoC FPGA】6.PipeCNN代码精读 | ANG404's Blog</title><meta name="author" content="ANG404"><meta name="copyright" content="ANG404"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="请先阅读完OpenCL基础章节和程序设计流程章节再阅读本章。">
<meta property="og:type" content="article">
<meta property="og:title" content="【SoC FPGA】6.PipeCNN代码精读">
<meta property="og:url" content="https://ang404me.github.io/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/index.html">
<meta property="og:site_name" content="ANG404&#39;s Blog">
<meta property="og:description" content="请先阅读完OpenCL基础章节和程序设计流程章节再阅读本章。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&w=3870&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D">
<meta property="article:published_time" content="2023-09-15T06:41:08.000Z">
<meta property="article:modified_time" content="2023-09-15T06:41:08.000Z">
<meta property="article:author" content="ANG404">
<meta property="article:tag" content="SoC FPGA">
<meta property="article:tag" content="de10_nano">
<meta property="article:tag" content="OpenCL">
<meta property="article:tag" content="PipeCNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&w=3870&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://ang404me.github.io/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"KO507S2B4N","apiKey":"f97c3f82d7e1bfd4384590360f0bad75","indexName":"hexo","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":3000,"languages":{"author":"作者: ANG404","link":"链接: ","source":"来源: ANG404's Blog","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: false,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【SoC FPGA】6.PipeCNN代码精读',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-09-15 14:41:08'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/mycss.css"><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DibbupDOTKvQMfAaYkjlvq4nR5Zkxd8ebYiauKfmGDGzYHbP5xhEG0FXkCoT3KaC8xe7WguiaKLA3AzNuYGe2V8ibg/132" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 足迹</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影片</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&amp;w=3870&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D')"><nav id="nav"><span id="blog-info"><a href="/" title="ANG404's Blog"><span class="site-name">ANG404's Blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 足迹</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/Gallery/"><i class="fa-fw fas fa-images"></i><span> 照片</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影片</span></a></li></ul></div><div class="menus_item"><a class="site-page group hide" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【SoC FPGA】6.PipeCNN代码精读</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-09-15T06:41:08.000Z" title="发表于 2023-09-15 14:41:08">2023-09-15</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-09-15T06:41:08.000Z" title="更新于 2023-09-15 14:41:08">2023-09-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/SoC-FPGA/">SoC FPGA</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【SoC FPGA】6.PipeCNN代码精读"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1>PipeCNN代码精读</h1>
<blockquote>
<p>源代码：<a target="_blank" rel="noopener" href="https://github.com/doonny/PipeCNN.git">https://github.com/doonny/PipeCNN.git</a></p>
</blockquote>
<h2 id="一、OpenCL基础">一、OpenCL基础</h2>
<h3 id="1-1、host程序编程步骤">1.1、host程序编程步骤</h3>
<p><img src="https://cdn.buct-alcp.top/20230905170530.png" alt=""></p>
<h2 id="二、host代码">二、host代码</h2>
<h3 id="2-1、代码目录">2.1、代码目录</h3>
<ul>
<li>host
<ul>
<li>main.cpp：host代码</li>
<li>layer_config.h：网络结构</li>
</ul>
</li>
<li>device
<ul>
<li>conv_pipe.cl：kernel代码</li>
<li>hw_param.cl：硬件参数配置，针对不同型号fpga配置不同的参数已适配其资源。</li>
<li>RTL文件夹：其中包含一个8位的矢量乘法器ip。</li>
</ul>
</li>
<li>以下章节是按照逻辑顺序排列，而不是单单是代码顺序。</li>
</ul>
<h3 id="2-2、main-cpp头文件、定义">2.2、main.cpp头文件、定义</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//////////////////////////////////////////</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// OpenCL host program template for multiple</span></span><br><span class="line"><span class="comment">// FPGA boards.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// Created by dongwang@2016.01.10</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">/////////////////////////////////////////</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;math.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;CL/opencl.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// user defined library</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;ocl_util.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;timer.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">// CNN network configuration file</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;../device/hw_param.cl&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;layer_config.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_OPENCV</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;opencv2/core/core.hpp&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> cv;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> ocl_util;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span>  <span class="type">signed</span> <span class="type">char</span>  DTYPE;</span><br><span class="line"><span class="keyword">typedef</span>  <span class="type">float</span> FTYPE;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> XILINX</span></span><br><span class="line"><span class="comment">//#define USE_SDX_1DDR  // reserved for v7-690T device, DO NOT USE</span></span><br><span class="line"><span class="comment">//#define USE_SDX_4DDR  // reserved for v7-690T device, DO NOT USE</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="comment">//----------- Design Parameters --------------//</span></span><br><span class="line"><span class="comment">// select what platform is used</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> XILINX</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *vendor_name = <span class="string">&quot;Xilinx&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="comment">//----------- SDK version &lt;= 19.1 -----------//</span></span><br><span class="line"><span class="comment">//const char *vendor_name = &quot;Intel&quot;;</span></span><br><span class="line"><span class="comment">//----------- SDK version &gt;= 19.3 ----------//</span></span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(SW_EMU)</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *vendor_name = <span class="string">&quot;Intel(R) FPGA Emulation Platform for OpenCL(TM)&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *vendor_name = <span class="string">&quot;Intel(R) FPGA SDK for OpenCL(TM)&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DEVICE_TYPE CL_DEVICE_TYPE_ACCELERATOR</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// SW System parameters</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> DMA_ALIGNMENT   64</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_LAYER_NUM   54</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_BATCH_SIZE  16</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> IN_BUF_SIZE    256*256*128  <span class="comment">// Note: the buffer size should be large enough to hold all temporary results</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> OUT_BUF_SIZE   256*256*128</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> POOL_BUF_SIZE  256*256*128</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> FC_BUF_SIZE    32768*MAX_BATCH_SIZE</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MEAN_DATA_WIDTH   256</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MEAN_DATA_HEIGHT  256</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MEAN_DATA_CHANNEl 3</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> PICTURE_NUM 8000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAX_PIC_NUM 50000</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *mean_data_file_path    = <span class="string">&quot;./data/imagenet/mean_data.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *synset_word_file_path  = <span class="string">&quot;./data/imagenet/synset_words.txt&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *LabelPath              = <span class="string">&quot;./data/imagenet/val.txt&quot;</span>;</span><br><span class="line"><span class="type">char</span>  picture_file_path_head[<span class="number">100</span>]  = <span class="string">&quot;/home/dwang/Work/imagenet/ilsvrc2012/ILSVRC2012_img_val/ILSVRC2012_val_&quot;</span>;</span><br><span class="line"><span class="type">char</span>  picture_file_path[<span class="number">100</span>];</span><br><span class="line"><span class="type">int</span>   label[MAX_PIC_NUM]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="type">char</span>  label_buf[MAX_PIC_NUM][<span class="number">1024</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="type">char</span>  synset_buf[<span class="number">1000</span>][<span class="number">1024</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">DTYPE searchTop[<span class="number">1024</span>];</span><br><span class="line"><span class="type">float</span> accuracy1=<span class="number">0</span>;</span><br><span class="line"><span class="type">float</span> accuracy5=<span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">// Test FC only</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers</span></span><br><span class="line"><span class="comment">#define IMAGE_FILE_SIZE   (27*27*96)</span></span><br><span class="line"><span class="comment">//#define WEIGHTS_FILE_SIZE 60965224 //fc8-1000</span></span><br><span class="line"><span class="comment">#define WEIGHTS_FILE_SIZE 61063552  //fc8-1024</span></span><br><span class="line"><span class="comment">#define CONV_NUM          4</span></span><br><span class="line"><span class="comment">#define LAYER_NUM         7</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">const char *weight_file_path = &quot;./data/data_alex/weights.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *input_file_path = &quot;./data/data_alex/lrn1.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *ref_file_path = &quot;./data/data_alex/fc8.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *dump_file_path = &quot;./result_dump.txt&quot;;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">// Test FC only</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers</span></span><br><span class="line"><span class="comment">#define IMAGE_FILE_SIZE   (6*6*256)</span></span><br><span class="line"><span class="comment">//#define WEIGHTS_FILE_SIZE 60965224 //fc8-1000</span></span><br><span class="line"><span class="comment">#define WEIGHTS_FILE_SIZE 61063552  //fc8-1024</span></span><br><span class="line"><span class="comment">#define CONV_NUM          0</span></span><br><span class="line"><span class="comment">#define LAYER_NUM         3</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">const char *weight_file_path = &quot;./data/data_alex/weights.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *input_file_path = &quot;./data/data_alex/pool5.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *ref_file_path = &quot;./data/data_alex/fc8.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *dump_file_path = &quot;./result_dump.txt&quot;;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">// Test CONV only</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers</span></span><br><span class="line"><span class="comment">#define IMAGE_FILE_SIZE   (227*227*3)</span></span><br><span class="line"><span class="comment">//#define WEIGHTS_FILE_SIZE 60965224 //fc8-1000</span></span><br><span class="line"><span class="comment">#define WEIGHTS_FILE_SIZE 61063552  //fc8-1024</span></span><br><span class="line"><span class="comment">#define LAYER_NUM         2</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">const char *weight_file_path = &quot;./data/data_alex/weights.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *input_file_path = &quot;./data/data_alex/image.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *ref_file_path = &quot;./data/data_alex/pool2.dat&quot;;</span></span><br><span class="line"><span class="comment">const char *dump_file_path = &quot;./result_dump.txt&quot;;</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ALEXNET</span></span><br><span class="line"><span class="comment">// AlexNet</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers </span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> IMAGE_FILE_SIZE   (227*227*3)</span></span><br><span class="line"><span class="comment">//#define WEIGHTS_FILE_SIZE 60965224 //fc8-1000</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> WEIGHTS_FILE_SIZE 61063552  <span class="comment">//fc8-1024</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LAYER_NUM         8<span class="comment">//8</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONV_NUM          5</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *weight_file_path = <span class="string">&quot;./data/data_alex/weights.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *input_file_path = <span class="string">&quot;./data/data_alex/image.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *ref_file_path = <span class="string">&quot;./data/data_alex/fc8.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *dump_file_path = <span class="string">&quot;./result_dump.txt&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> VGG16</span></span><br><span class="line"><span class="comment">// VGG16</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> IMAGE_FILE_SIZE   (224*224*3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> WEIGHTS_FILE_SIZE 138455872  <span class="comment">//fc8-1024</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LAYER_NUM         16</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONV_NUM          13</span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *weight_file_path = <span class="string">&quot;./data/data_vgg/weights.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *input_file_path = <span class="string">&quot;./data/data_vgg/image.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *ref_file_path = <span class="string">&quot;./data/data_vgg/fc8.dat&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *dump_file_path = <span class="string">&quot;./result_dump.txt&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span> </span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line"><span class="comment">// ResNet</span></span><br><span class="line"><span class="comment">// Original problem size</span></span><br><span class="line"><span class="comment">// File size is in num of DTYPE numbers</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> IMAGE_FILE_SIZE		(224*224*3)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> WEIGHTS_FILE_SIZE	25579648</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MEAN_FILE_SIZE 		26560</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> VAR_FILE_SIZE		26560</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> ALPHA_FILE_SIZE		26560</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BETA_FILE_SIZE		26560</span></span><br><span class="line"><span class="comment">//#define LAYER_NUM         	54</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> LAYER_NUM         	54</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> CONV_NUM         	53</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *weight_file_path = <span class="string">&quot;./data/data_resnet/weights_qt.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *mean_file_path = <span class="string">&quot;./data/data_resnet/mean.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *var_file_path = <span class="string">&quot;./data/data_resnet/var.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *alpha_file_path = <span class="string">&quot;./data/data_resnet/alpha.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *beta_file_path = <span class="string">&quot;./data/data_resnet/beta.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *input_file_path = <span class="string">&quot;./data/data_resnet/image.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *ref_file_path = <span class="string">&quot;./data/data_resnet/fc1024.data&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *dump_file_path = <span class="string">&quot;./result_dump.txt&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="comment">//ResNet maxpool need padding</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXPOOL_PAD 1</span></span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> MAXPOOL_PAD 0</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<h3 id="2-3、main-cpp配置文件的结构（与layer-config-h文件相关）">2.3、main.cpp配置文件的结构（与layer_config.h文件相关）</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Configuration file instructions</span></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">config_item</span>&#123;</span><br><span class="line">layer_type, <span class="comment">// &quot;0&quot; -&gt; conv, &quot;1&quot; -&gt; fc</span></span><br><span class="line"></span><br><span class="line">data_w, data_h, data_n, weight_w, weight_h, weight_n, weight_m, bias_size, <span class="comment">//memRd Parameters</span></span><br><span class="line"></span><br><span class="line">memrd_src, <span class="comment">//&quot;0&quot;-&gt; data_buf  &quot;1&quot;-&gt; output_buf  &quot;2&quot;-&gt;&quot;fc_1_buffer&quot;  &quot;3&quot;-&gt;&quot;fc_2_buffer&quot;  &quot;4&quot;-&gt;&quot;pool_buffer&quot; &quot;5&quot;-&gt;&quot;eltwise_buf&quot;(resnet)</span></span><br><span class="line"></span><br><span class="line">conv_x, conv_y, conv_z, conv_stride, conv_padding, conv_split, conv_relu, <span class="comment">//Conv Parameters</span></span><br><span class="line"></span><br><span class="line">pool_on, pool_x, pool_y, pool_z, pool_size, pool_stride, <span class="comment">// Pooling Parameters</span></span><br><span class="line"></span><br><span class="line">lrn_on,<span class="comment">// lrn on/off control</span></span><br><span class="line"></span><br><span class="line">memwr_dst<span class="comment">//&quot;0&quot;-&gt; data_buf  &quot;1&quot;-&gt; output_buf  &quot;2&quot;-&gt;&quot;fc_1_buffer&quot;  &quot;3&quot;-&gt;&quot;fc_2_buffer&quot;</span></span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">input_item</span>&#123;</span><br><span class="line"></span><br><span class="line">image_w, image_h, image_n, <span class="comment">// original image size</span></span><br><span class="line"></span><br><span class="line">batch_size</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">output_item</span>&#123;</span><br><span class="line"></span><br><span class="line">output_w, output_h, output_n</span><br><span class="line"></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">enum</span> <span class="title class_">precision_item</span>&#123;</span><br><span class="line"></span><br><span class="line">frac_w, frac_din, frac_dout</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>config_item定义了CNN中每层的各种参数，包括：输入特征图尺寸、卷积核尺寸、输入buffer、输出特征图尺寸、是否通过lrn层、输出buffer。</li>
<li>config_item定义了第一次输入图像尺寸。</li>
<li>output_item定义了最后一层输出尺寸。</li>
<li>precision_item为各层的精度控制字。</li>
</ul>
<h3 id="2-4、main-cpp声明变量与函数">2.4、main.cpp声明变量与函数</h3>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Define the kernel names used</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_memRd = <span class="string">&quot;memRead&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_conv  = <span class="string">&quot;coreConv&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_Pool  = <span class="string">&quot;maxPool&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_memWr = <span class="string">&quot;memWrite&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_lrn   = <span class="string">&quot;lrn&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_bn   = <span class="string">&quot;batchNorm&quot;</span>;</span><br><span class="line"><span class="type">const</span> <span class="type">char</span> *knl_name_elt   = <span class="string">&quot;eltwise&quot;</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//------------ Global Functions &amp; Variables ------------//</span></span><br><span class="line">cl_uint num_devices = <span class="number">0</span>;</span><br><span class="line">cl_platform_id platform_id = <span class="literal">NULL</span>;</span><br><span class="line">cl_context context = <span class="literal">NULL</span>;</span><br><span class="line">cl_program program = <span class="literal">NULL</span>;</span><br><span class="line">scoped_array&lt;cl_device_id&gt; device;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_memRd;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_conv;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_memWr;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_pool;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_lrn;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_memRd;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_conv;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_memWr;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_pool;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_lrn;</span><br><span class="line">scoped_array&lt;cl_mem&gt; data_buf;	<span class="comment">// data_buf、output_buf两个buffer用于pipeline</span></span><br><span class="line">scoped_array&lt;cl_mem&gt; output_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; pool_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; weights_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; bias_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; fc_1_buf;	<span class="comment">// 两个buffer用于pipeline</span></span><br><span class="line">scoped_array&lt;cl_mem&gt; fc_2_buf;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_bn;</span><br><span class="line">scoped_array&lt;cl_command_queue&gt; que_bn;</span><br><span class="line">scoped_array&lt;cl_kernel&gt; knl_elt;</span><br><span class="line">scoped_array&lt;cl_mem&gt; mean_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; var_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; alpha_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; beta_buf;</span><br><span class="line">scoped_array&lt;cl_mem&gt; eltwise_buf;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> XILINX</span></span><br><span class="line">	<span class="function">scoped_array&lt;cl_event&gt; <span class="title">write_event</span><span class="params">(num_devices)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="comment">//DO NOTHING</span></span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">DTYPE *weights;</span><br><span class="line">DTYPE *image;</span><br><span class="line">DTYPE *data_init;</span><br><span class="line">DTYPE *weight_conv[MAX_LAYER_NUM];</span><br><span class="line">DTYPE *bias_conv[MAX_LAYER_NUM];</span><br><span class="line">DTYPE *output;</span><br><span class="line">DTYPE *output_one_item;</span><br><span class="line">DTYPE *output_reorder;</span><br><span class="line">DTYPE *golden_ref;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">FTYPE *means;</span><br><span class="line">FTYPE *var;</span><br><span class="line">FTYPE *alpha;</span><br><span class="line">FTYPE *beta;</span><br><span class="line">FTYPE *mean_conv[MAX_LAYER_NUM];</span><br><span class="line">FTYPE *var_conv[MAX_LAYER_NUM];</span><br><span class="line">FTYPE *alpha_conv[MAX_LAYER_NUM];</span><br><span class="line">FTYPE *beta_conv[MAX_LAYER_NUM];</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="type">unsigned</span> layer_config_original[LAYER_NUM][NUM_CONFIG_ITEM];</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_OPENCV</span></span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">load_picture</span><span class="params">(DTYPE *image)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">getAccuracy</span><span class="params">(DTYPE *output_reorder,<span class="type">int</span> num)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">labelNum</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">numtochar</span><span class="params">(<span class="type">int</span> num,<span class="type">char</span> *end)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderMVAB</span><span class="params">(FTYPE *dataIn, FTYPE *dataout, <span class="type">unsigned</span> offset, <span class="type">unsigned</span> padding_offset, <span class="type">unsigned</span> dim4, <span class="type">unsigned</span> dim4_original, <span class="type">unsigned</span> laneNum)</span></span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">loadImageToBuffer</span><span class="params">(<span class="type">int</span> num)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span>  <span class="title">prepare</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">readDataBack</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">verifyResult</span><span class="params">(<span class="type">int</span> num)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dumpResult</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderWeights</span><span class="params">(DTYPE *weights, DTYPE *weight_buf, <span class="type">unsigned</span> dim1, <span class="type">unsigned</span> dim2, <span class="type">unsigned</span> dim3, <span class="type">unsigned</span> dim4, <span class="type">unsigned</span> dim3_original, <span class="type">unsigned</span> dim4_original, <span class="type">unsigned</span> offset, <span class="type">unsigned</span> padding_offset, <span class="type">unsigned</span> vecSize, <span class="type">unsigned</span> laneNum)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderBias</span><span class="params">(DTYPE *dataIn, DTYPE *bias, <span class="type">unsigned</span> offset, <span class="type">unsigned</span> padding_offset, <span class="type">unsigned</span> dim4, <span class="type">unsigned</span> dim4_original, <span class="type">unsigned</span> laneNum)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderOutput</span><span class="params">(DTYPE *output, DTYPE *output_reorder, <span class="type">unsigned</span> dim1, <span class="type">unsigned</span> dim2, <span class="type">unsigned</span> dim3)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">extractOutput</span><span class="params">(DTYPE *output, DTYPE *output_one_item, <span class="type">unsigned</span> item_num, <span class="type">unsigned</span> batch_size, <span class="type">unsigned</span> dim1, <span class="type">unsigned</span> dim2, <span class="type">unsigned</span> dim3)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">softmax</span><span class="params">(DTYPE *output_reorder , DTYPE *output)</span></span>;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">getProb</span><span class="params">(DTYPE *output)</span></span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">cleanup</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure>
<h3 id="2-5、-main-cpp主函数部分">2.5、*main.cpp主函数部分</h3>
<h4 id="①-连接平台">① 连接平台</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Connect to the desired platform</span></span><br><span class="line">platform_id = <span class="built_in">findPlatform</span>(vendor_name);</span><br><span class="line"><span class="keyword">if</span>(platform_id == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;ERROR: Unable to find the desired OpenCL platform.\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="②-打印可用的OpenCL平台">② 打印可用的OpenCL平台</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Query the available OpenCL device</span></span><br><span class="line">device.<span class="built_in">reset</span>(<span class="built_in">getDevices</span>(platform_id, DEVICE_TYPE, &amp;num_devices));</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;\nPlatform: %s\n&quot;</span>, <span class="built_in">getPlatformName</span>(platform_id).<span class="built_in">c_str</span>());</span><br><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;Totally %d device(s) are found\n&quot;</span>, num_devices);</span><br></pre></td></tr></table></figure>
<h4 id="③-打印设备名称">③ 打印设备名称</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">printf</span>(<span class="string">&quot;  Using Device %d: %s\n&quot;</span>, device_ptr, <span class="built_in">getDeviceName</span>(device[device_ptr]).<span class="built_in">c_str</span>());</span><br><span class="line"><span class="built_in">displayDeviceInfo</span>(device[device_ptr]);</span><br></pre></td></tr></table></figure>
<h4 id="④-创建上下文">④ 创建上下文</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">context = <span class="built_in">clCreateContext</span>(<span class="literal">NULL</span>, num_devices, &amp;device[device_ptr], <span class="literal">NULL</span>, <span class="literal">NULL</span>, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create context&quot;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="⑤-创建程序对象">⑤ 创建程序对象</h4>
<p>对所有的device创建程序对象，执行相同的kernel.</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create Program Objects</span></span><br><span class="line"><span class="type">char</span> *kernel_file_name=argv[<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">// Create the program for all device. All devices execute the same kernel.</span></span><br><span class="line">program = <span class="built_in">createProgramFromFile</span>(context, (<span class="type">const</span> <span class="type">char</span> *) kernel_file_name, &amp;device[device_ptr], num_devices);</span><br></pre></td></tr></table></figure>
<h4 id="⑥-创建一组缓冲区和对象">⑥ 创建一组缓冲区和对象</h4>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create per-device objects.</span></span><br><span class="line">que_memRd.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">que_conv.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">que_memWr.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">que_pool.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">que_lrn.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">knl_memRd.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">knl_conv.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">knl_memWr.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">knl_pool.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">knl_lrn.<span class="built_in">reset</span>(num_devices);</span><br><span class="line"><span class="comment">// For each layer a group of buffers are created to store the weights and bias</span></span><br><span class="line">weights_buf.<span class="built_in">reset</span>(num_devices*LAYER_NUM);</span><br><span class="line">bias_buf.<span class="built_in">reset</span>(num_devices*LAYER_NUM);</span><br><span class="line"><span class="comment">// Two buffers (data and output) are used as ping-pong buffers for conv layers</span></span><br><span class="line">data_buf.<span class="built_in">reset</span>(num_devices*MAX_BATCH_SIZE);</span><br><span class="line">output_buf.<span class="built_in">reset</span>(num_devices*MAX_BATCH_SIZE);</span><br><span class="line">pool_buf.<span class="built_in">reset</span>(num_devices*MAX_BATCH_SIZE);</span><br><span class="line"><span class="comment">// Two buffers are used as ping-pong buffers for fc layers</span></span><br><span class="line">fc_1_buf.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">fc_2_buf.<span class="built_in">reset</span>(num_devices);</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">	knl_bn.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">	que_bn.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">	knl_elt.<span class="built_in">reset</span>(num_devices);</span><br><span class="line">	mean_buf.<span class="built_in">reset</span>(num_devices*CONV_NUM);</span><br><span class="line">	var_buf.<span class="built_in">reset</span>(num_devices*CONV_NUM);</span><br><span class="line">	alpha_buf.<span class="built_in">reset</span>(num_devices*CONV_NUM);</span><br><span class="line">	beta_buf.<span class="built_in">reset</span>(num_devices*CONV_NUM);</span><br><span class="line">	eltwise_buf.<span class="built_in">reset</span>(num_devices*MAX_BATCH_SIZE);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure>
<ol>
<li><code>que_memRd.reset(num_devices);</code> 到 <code>knl_lrn.reset(num_devices);</code>：这一部分创建了一组对象，每个对象代表一个设备（device），通常用于并行计算。这些对象可能是任务队列或类似的数据结构，用于调度和执行不同设备上的计算任务。<code>num_devices</code> 是设备数量，根据系统配置可以是一个或多个。</li>
<li><code>weights_buf.reset(num_devices*LAYER_NUM);</code> 和 <code>bias_buf.reset(num_devices*LAYER_NUM);</code>：这两行创建了用于存储神经网络中权重（weights）和偏置（bias）的缓冲区。<code>num_devices</code> 表示设备数量，<code>LAYER_NUM</code> 表示神经网络的层数。因此，这些缓冲区的数量是设备数量和层数的乘积。</li>
<li><code>data_buf.reset(num_devices*MAX_BATCH_SIZE);</code>、<code>output_buf.reset(num_devices*MAX_BATCH_SIZE);</code> 和 <code>pool_buf.reset(num_devices*MAX_BATCH_SIZE);</code>：这三行创建了用于存储神经网络中数据（例如输入数据、中间层的输出和池化层的输出）的缓冲区。<code>num_devices</code> 表示设备数量，<code>MAX_BATCH_SIZE</code> 表示每个批次（batch）的数据大小。因此，这些缓冲区的数量是设备数量和批次大小的乘积。</li>
<li><code>fc_1_buf.reset(num_devices);</code> 和 <code>fc_2_buf.reset(num_devices);</code>：这两行创建了用于存储全连接层（fully connected layer）的中间结果的缓冲区。全连接层通常是神经网络的最后一层，用于输出最终的分类或回归结果。</li>
</ol>
<h4 id="⑦-prepare-函数">⑦ prepare()函数</h4>
<p><strong>调用：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Prepare compute data</span></span><br><span class="line">status = <span class="built_in">prepare</span>();</span><br><span class="line"><span class="keyword">if</span>(status == <span class="number">1</span>)&#123;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">&quot;Allocate memory for data and weights failed !!!\n&quot;</span>);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>prepare()函数：</strong></p>
<h5 id="〇、ptr参数">〇、ptr参数</h5>
<p>ptr为每层的<strong>原始</strong>权重和偏置的偏移地址（offset address）。</p>
<h5 id="Ⅰ、参数初始化与安全检查">Ⅰ、参数初始化与安全检查</h5>
<p>第一步，备份原始层配置信息；</p>
<p>第二步，如果weight_m(weight_dim4，卷积核个数)不能被LANE_NUM整除，则对weight_m两端padding，如果weight_m不被2整除则报错。注意：这里没有进行补零操作，而是提供了padding_offset[ll]。最后检查每层的参数。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">// Parameter initialization and safty check</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> ll=<span class="number">0</span>; ll&lt;LAYER_NUM; ll++)&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// First, backup the original layer configurations</span></span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> ii=<span class="number">0</span>; ii&lt;NUM_CONFIG_ITEM; ii++)&#123;</span><br><span class="line">			layer_config_original[ll][ii]=layer_config[ll][ii];</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Second, perform padding on dim4, when it is not divisible by LANE_NUM</span></span><br><span class="line">		<span class="keyword">if</span>(layer_config[ll][weight_m]%LANE_NUM != <span class="number">0</span>)&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;\nWarnning: layer-%d requires padding zero-value feature maps for give param LANE_NUM=%d\n&quot;</span>, ll+<span class="number">1</span>, LANE_NUM);</span><br><span class="line">			<span class="comment">// change the num of output featuremaps to new value that is divisible by LANE_NUM</span></span><br><span class="line">			<span class="comment">// Note: the num of input feature maps of next layer remains the same</span></span><br><span class="line">			layer_config[ll][weight_m] = <span class="built_in">ceil</span>((<span class="type">float</span>)layer_config[ll][weight_m]/LANE_NUM)*LANE_NUM;</span><br><span class="line">			layer_config[ll][bias_size] = layer_config[ll][weight_m];</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;      original num of feature maps is %d, new value is %d\n&quot;</span>, layer_config_original[ll][weight_m], layer_config[ll][weight_m]);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// padding of weight on dim4 is needed</span></span><br><span class="line">			padding_offset[ll] = layer_config[ll][weight_m] - layer_config_original[ll][weight_m];</span><br><span class="line">			<span class="comment">// check if evenly padding on two sides is possible</span></span><br><span class="line">			<span class="keyword">if</span>(((layer_config[ll][weight_m]/LANE_NUM)%<span class="number">2</span>!=<span class="number">0</span>) &amp; (layer_config[ll][conv_split]==<span class="number">1</span>))&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;Error: could not perform padding for split mode, weight_m/LANE_NUM must be divisible by 2 !!!\n\n&quot;</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">else</span>&#123; <span class="comment">// padding zeros evenly on two sides of dim4</span></span><br><span class="line">				padding_offset[ll] = padding_offset[ll]/<span class="number">2</span>;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;      padding_offset=%d (layer=%d)\n\n&quot;</span>, padding_offset[ll], ll+<span class="number">1</span>);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123;</span><br><span class="line">			padding_offset[ll] = <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// Check parameters</span></span><br><span class="line">		<span class="keyword">if</span>(ll==<span class="number">0</span>)&#123; <span class="comment">// check parameters for layer-1</span></span><br><span class="line">			<span class="keyword">if</span>(input_config[image_w] != layer_config_original[ll][data_w] ||  input_config[image_h] != layer_config_original[ll][data_h]</span><br><span class="line">				|| input_config[image_n] != layer_config_original[ll][data_n] || input_config[image_n] != layer_config_original[ll][weight_n])&#123;</span><br><span class="line">					<span class="built_in">printf</span>(<span class="string">&quot;Error: incorrect layer configuration for layer-%d !!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">					<span class="comment">//return 1;</span></span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">if</span>((layer_config_original[ll][weight_n]!=input_config[image_n]))&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect layer configuration for layer-%d !!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">				<span class="comment">//return 1;</span></span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123; <span class="comment">// other layers</span></span><br><span class="line"></span><br><span class="line">			<span class="comment">// Currently weight_n must be divisible by VEC_SIZE (for first layer, padding is performed when weight_n is not divisible by VEC_SIZE)</span></span><br><span class="line">			<span class="keyword">if</span>((layer_config[ll][weight_n]%VEC_SIZE)!=<span class="number">0</span>)&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect setting of parameter VEC_SIZE !!!\n&quot;</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">			<span class="keyword">if</span>((layer_config_original[ll][data_n]!=layer_config_original[eltwise_layer_previous[ll]<span class="number">-1</span>][conv_z]))&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect setting of convolution input/output size for layer-%d!!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">			<span class="keyword">if</span>((layer_config_original[ll][data_n]!=layer_config_original[ll<span class="number">-1</span>][conv_z]))&#123;</span><br><span class="line">				<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect setting of convolution input/output size for layer-%d!!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">				<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">if</span>((layer_config_original[ll][conv_x]!=(layer_config_original[ll][data_w]-layer_config_original[ll][weight_w]+<span class="number">2</span>*layer_config_original[ll][conv_padding])/layer_config_original[ll][conv_stride]+<span class="number">1</span>)</span><br><span class="line">			|| (layer_config_original[ll][conv_y]!=(layer_config_original[ll][data_h]-layer_config_original[ll][weight_h]+<span class="number">2</span>*layer_config_original[ll][conv_padding])/layer_config_original[ll][conv_stride]+<span class="number">1</span>)</span><br><span class="line">		    || (layer_config_original[ll][conv_z]!=layer_config_original[ll][weight_m]))&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect setting of convolution output size or filter params for layer-%d!!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">			<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">//ResNet maxPool need pad</span></span><br><span class="line">		<span class="keyword">if</span>((layer_config_original[ll][pool_on]==<span class="number">1</span>) &amp;&amp; ((layer_config_original[ll][pool_x]!=((layer_config_original[ll][conv_x]+MAXPOOL_PAD)-layer_config_original[ll][pool_size])/layer_config_original[ll][pool_stride]+<span class="number">1</span>)</span><br><span class="line">			|| (layer_config_original[ll][pool_y]!=((layer_config_original[ll][conv_y]+MAXPOOL_PAD)-layer_config_original[ll][pool_size])/layer_config_original[ll][pool_stride]+<span class="number">1</span>)</span><br><span class="line">		    || (layer_config_original[ll][pool_z]!=layer_config_original[ll][conv_z])))&#123;</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;\nError: incorrect setting of pooling input/output size for layer-%d!!!\n&quot;</span>, ll+<span class="number">1</span>);</span><br><span class="line">			<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// <span class="doctag">TODO:</span> check buffer size, hw params</span></span><br><span class="line">		<span class="keyword">if</span>(layer_config[ll][conv_x]==<span class="number">1</span>)&#123; <span class="comment">// when only one group for FC layer</span></span><br><span class="line">			conv_win_size_dim1  = layer_config[ll][weight_w];</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123;</span><br><span class="line">			conv_win_size_dim1  = layer_config[ll][weight_w]+(CONV_GP_SIZE_X<span class="number">-1</span>)*layer_config[ll][conv_stride];</span><br><span class="line">		&#125;</span><br><span class="line">		conv_win_size_dim2    = layer_config[ll][weight_h];</span><br><span class="line">		<span class="comment">// check win_buffer size</span></span><br><span class="line">		<span class="keyword">if</span>(conv_win_size_dim1*conv_win_size_dim2*layer_config[ll][weight_n]/VEC_SIZE &gt; WIN_BUF_SIZE)&#123;</span><br><span class="line"></span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Error: required win_buffer size is %d, configured size is %d \n&quot;</span>, conv_win_size_dim1*conv_win_size_dim2*layer_config[ll][weight_n]/VEC_SIZE, WIN_BUF_SIZE);</span><br><span class="line">			<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// check weight_buffer size</span></span><br><span class="line">		<span class="keyword">if</span>(layer_config[ll][weight_w]*layer_config[ll][weight_h]*layer_config[ll][weight_n]/VEC_SIZE &gt; WEIGHT_BUF_SIZE)&#123;</span><br><span class="line"></span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Error: required weight_buffer size is %d, configured size is %d \n&quot;</span>, layer_config[ll][weight_w]*layer_config[ll][weight_h]*layer_config[ll][weight_n]/VEC_SIZE, WEIGHT_BUF_SIZE);</span><br><span class="line">			<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅱ、为weights-dat和image-dat分配空间">Ⅱ、为weights.dat和image.dat分配空间</h5>
<p>这里的<strong>weights</strong>是一整块内存，用于存储weights.dat，weights.dat包含了weights和bias；<strong>image</strong>用于存储原始图片image.dat。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// image and weight files</span></span><br><span class="line">weights      = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*WEIGHTS_FILE_SIZE, DMA_ALIGNMENT);</span><br><span class="line">image        = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*IMAGE_FILE_SIZE, DMA_ALIGNMENT);</span><br></pre></td></tr></table></figure>
<h5 id="Ⅲ、输入图像通道padding">Ⅲ、输入图像通道padding</h5>
<p>对输入原图的data_n和weight_n（rgb通道数=3）进行padding，使其能被VEC_SIZE整除。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// input data buffers</span></span><br><span class="line"><span class="comment">// padding the input RGB image with extra number of zeros channels, so that data_n/weight_n is divisible by VEC_SIZE</span></span><br><span class="line">layer_config[<span class="number">0</span>][weight_n] = <span class="built_in">ceil</span>((<span class="type">float</span>)layer_config[<span class="number">0</span>][weight_n]/VEC_SIZE)*VEC_SIZE;</span><br><span class="line">layer_config[<span class="number">0</span>][data_n] = layer_config[<span class="number">0</span>][weight_n];</span><br></pre></td></tr></table></figure>
<h5 id="Ⅳ、为data-init分配空间">Ⅳ、为data_init分配空间</h5>
<p>不属于RGB通道的其他通道赋值为0。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data_init   = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*layer_config[<span class="number">0</span>][data_w]*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_n], DMA_ALIGNMENT);</span><br><span class="line"><span class="built_in">memset</span>(data_init, <span class="number">0</span>, <span class="built_in">sizeof</span>(DTYPE)*layer_config[<span class="number">0</span>][data_w]*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_n]);<span class="comment">// fill non-RGB dims with 0</span></span><br></pre></td></tr></table></figure>
<h5 id="Ⅴ、为输出变量分配空间">Ⅴ、为输出变量分配空间</h5>
<p>为output（向量化输出）、output_one_item、golden_ref、output_reorder分配空间。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// final results</span></span><br><span class="line">	<span class="keyword">if</span>(LAYER_NUM&gt;=CONV_NUM)<span class="comment">// For last conv and all fc layers, all batch results are read back</span></span><br><span class="line">		output_size = output_config[output_w]*output_config[output_h]*output_config[output_n]*input_config[batch_size];</span><br><span class="line">	<span class="keyword">else</span> <span class="comment">// For other conv layers, only one item of</span></span><br><span class="line">		output_size = output_config[output_w]*output_config[output_h]*output_config[output_n];</span><br><span class="line"></span><br><span class="line">	godref_size = output_config[output_w]*output_config[output_h]*output_config[output_n];</span><br><span class="line"></span><br><span class="line">	output          = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*output_size, DMA_ALIGNMENT); <span class="comment">// vectorized results</span></span><br><span class="line">	output_one_item = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*godref_size, DMA_ALIGNMENT); <span class="comment">// one item extracted from batch results</span></span><br><span class="line">	golden_ref      = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*godref_size, DMA_ALIGNMENT);</span><br><span class="line">    output_reorder  = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*godref_size, DMA_ALIGNMENT); <span class="comment">// reordered results for verifying</span></span><br></pre></td></tr></table></figure>
<h5 id="Ⅵ、为每层的weights和bias分配空间">Ⅵ、为每层的weights和bias分配空间</h5>
<p>为每层的weight_conv[LAYER_NUM]、bias_conv[LAYER_NUM]分配空间，并赋值为0。这里的weight_conv[LAYER_NUM]和bias_conv[LAYER_NUM]是经过reorder处理的、每一层的权重和偏置。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// weights and bias	buffers</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;LAYER_NUM; j++)&#123;</span><br><span class="line"></span><br><span class="line">	weight_size = (layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config[j][weight_n]*layer_config[j][weight_m]);</span><br><span class="line">	weight_conv[j] = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*weight_size, DMA_ALIGNMENT);</span><br><span class="line">	bias_conv[j]   = (DTYPE *)<span class="built_in">alignedMalloc</span>(<span class="built_in">sizeof</span>(DTYPE)*layer_config[j][bias_size], DMA_ALIGNMENT);</span><br><span class="line"></span><br><span class="line">	<span class="built_in">memset</span>(weight_conv[j], <span class="number">0</span>, <span class="built_in">sizeof</span>(DTYPE)*weight_size);             <span class="comment">// reset all value (include padding value) to zero</span></span><br><span class="line">	<span class="built_in">memset</span>(bias_conv[j], <span class="number">0</span>, <span class="built_in">sizeof</span>(DTYPE)*layer_config[j][bias_size]);<span class="comment">// reset all value (include padding value) to zero</span></span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(weight_conv[j] == <span class="literal">NULL</span> || bias_conv[j] == <span class="literal">NULL</span> )</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Not enough memory !!!&quot;</span>);</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;=j; i++)&#123;</span><br><span class="line">			<span class="built_in">alignedFree</span>(weight_conv[i]);</span><br><span class="line">			<span class="built_in">alignedFree</span>(bias_conv[i]);</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅶ、写入数据">Ⅶ、写入数据</h5>
<ul>
<li>将weights.dat数据写入weights中</li>
<li>将synset_words.txt写入synset_buf中</li>
<li>将fc8.dat写入golden_ref中</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">	<span class="comment">// Weights</span></span><br><span class="line">	bin_file_r.<span class="built_in">open</span>(weight_file_path, ios::in | ios::binary);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(bin_file_r.<span class="built_in">is_open</span>())</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//Get file size</span></span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.end);</span><br><span class="line">		file_size = bin_file_r.<span class="built_in">tellg</span>();</span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.beg);</span><br><span class="line"></span><br><span class="line">		bin_file_r.<span class="built_in">read</span>((<span class="type">char</span> *)weights, <span class="built_in">sizeof</span>(DTYPE)*WEIGHTS_FILE_SIZE);</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;\n%d total weights read \n&quot;</span>, file_size/((<span class="type">int</span>)<span class="built_in">sizeof</span>(DTYPE)));</span><br><span class="line">		<span class="keyword">if</span>(WEIGHTS_FILE_SIZE!=(file_size/(<span class="built_in">sizeof</span>(DTYPE))))</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Warning: weight file size does not match user configuration !!!\n&quot;</span>);</span><br><span class="line">		bin_file_r.<span class="built_in">close</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Weights file does not exits !!!\n&quot;</span>);</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Synset_words</span></span><br><span class="line">     <span class="type">int</span> nn=<span class="number">0</span>;</span><br><span class="line">	 FILE *fp=<span class="built_in">fopen</span>(synset_word_file_path,<span class="string">&quot;r&quot;</span>);</span><br><span class="line">	 <span class="keyword">if</span>(!fp)</span><br><span class="line">	 &#123;</span><br><span class="line">		 <span class="built_in">printf</span>(<span class="string">&quot;Synset word file does not exits !!!\n&quot;</span>);</span><br><span class="line">		 <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	 &#125;</span><br><span class="line">	 <span class="keyword">while</span> (!<span class="built_in">feof</span>(fp))&#123;</span><br><span class="line">		<span class="built_in">fgets</span>(synset_buf[nn], <span class="number">1024</span>, fp);</span><br><span class="line">		nn++;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">fclose</span>(fp);</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_OPENCV</span></span><br><span class="line">	<span class="comment">// label</span></span><br><span class="line">	nn=<span class="number">0</span>;</span><br><span class="line">	fp=<span class="built_in">fopen</span>(LabelPath,<span class="string">&quot;r&quot;</span>);</span><br><span class="line">	<span class="keyword">if</span>(!fp)</span><br><span class="line">	&#123;</span><br><span class="line">		 <span class="built_in">printf</span>(<span class="string">&quot;Label file does not exits !!!\n&quot;</span>);</span><br><span class="line">		 <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	 &#125;</span><br><span class="line">	<span class="keyword">while</span> (!<span class="built_in">feof</span>(fp)&amp;&amp;nn&lt;PICTURE_NUM)&#123;</span><br><span class="line">		<span class="comment">//printf(&quot;read%d......\n&quot;,nn);</span></span><br><span class="line">		<span class="built_in">fgets</span>(label_buf[nn], <span class="number">1024</span>, fp);</span><br><span class="line">		nn++;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">fclose</span>(fp);</span><br><span class="line">	<span class="built_in">labelNum</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">	<span class="comment">// golden_output</span></span><br><span class="line">	bin_file_r.<span class="built_in">open</span>(ref_file_path, ios::in | ios::binary);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(bin_file_r.<span class="built_in">is_open</span>())</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="comment">//Get file size</span></span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.end);</span><br><span class="line">		file_size = bin_file_r.<span class="built_in">tellg</span>();</span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.beg);</span><br><span class="line"></span><br><span class="line">		bin_file_r.<span class="built_in">read</span>((<span class="type">char</span> *)golden_ref, <span class="built_in">sizeof</span>(DTYPE)*godref_size);</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;%d total output reference read \n\n&quot;</span>, file_size/((<span class="type">int</span>)<span class="built_in">sizeof</span>(DTYPE)));</span><br><span class="line">		<span class="keyword">if</span>(godref_size!=(file_size/(<span class="built_in">sizeof</span>(DTYPE))))</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Warning: golden reference file size does not match !!!\n&quot;</span>);</span><br><span class="line">		bin_file_r.<span class="built_in">close</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Golden file does not exits !!!\n&quot;</span>);</span><br></pre></td></tr></table></figure>
<h5 id="Ⅷ、-reorderWeights-、reorderBias-函数">Ⅷ、*reorderWeights()、reorderBias()函数</h5>
<p><strong>调用（第一层和其他层）：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Layer-1</span></span><br><span class="line"><span class="built_in">reorderWeights</span>(weights, weight_conv[<span class="number">0</span>], layer_config[<span class="number">0</span>][weight_w], layer_config[<span class="number">0</span>][weight_h], layer_config[<span class="number">0</span>][weight_n], layer_config[<span class="number">0</span>][weight_m], layer_config_original[<span class="number">0</span>][weight_n], layer_config_original[<span class="number">0</span>][weight_m], ptr, padding_offset[<span class="number">0</span>], VEC_SIZE, LANE_NUM);</span><br><span class="line">ptr+=layer_config[<span class="number">0</span>][weight_w]*layer_config[<span class="number">0</span>][weight_h]*layer_config_original[<span class="number">0</span>][weight_n]*layer_config_original[<span class="number">0</span>][weight_m];</span><br><span class="line"><span class="built_in">reorderBias</span>(weights, bias_conv[<span class="number">0</span>], ptr, padding_offset[<span class="number">0</span>], layer_config[<span class="number">0</span>][bias_size], layer_config_original[<span class="number">0</span>][bias_size], LANE_NUM);</span><br><span class="line">ptr+=layer_config_original[<span class="number">0</span>][bias_size];</span><br><span class="line"></span><br><span class="line"><span class="comment">// Other layers</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> j=<span class="number">1</span>; j&lt;LAYER_NUM; j++)&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(ptr+layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config_original[j][weight_n]*layer_config_original[j][weight_m]&gt;WEIGHTS_FILE_SIZE)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Error：exceed weight file size !!!\n&quot;</span>);</span><br><span class="line">		<span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="built_in">reorderWeights</span>(weights, weight_conv[j], layer_config[j][weight_w], layer_config[j][weight_h], layer_config[j][weight_n], layer_config[j][weight_m], layer_config_original[j][weight_n], layer_config_original[j][weight_m], ptr, padding_offset[j], VEC_SIZE, LANE_NUM);</span><br><span class="line">	ptr+=layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config_original[j][weight_n]*layer_config_original[j][weight_m];</span><br><span class="line">	<span class="built_in">reorderBias</span>(weights, bias_conv[j], ptr, padding_offset[j], layer_config[j][bias_size], layer_config_original[j][bias_size], LANE_NUM);</span><br><span class="line">	ptr+=layer_config_original[j][bias_size];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="reorderWeights"><strong>reorderWeights()</strong></h6>
<p>第一步，使用前文提到的padding_offset对weights的dim3、dim4进行padding，最后复制到copy_with_padding中。</p>
<p>第二步，将copy_with_padding的数据reorder后写入weight_conv[0]中。</p>
<p><strong>地址映射如下：</strong></p>
<blockquote>
<p>假设VEC_SIZE = 8, LANE_NUM = 4, 卷积核：dim1 = dim2 = 3, dim3 = 16, dim4 =32</p>
<p>原始权重weights：</p>
<p><img src="https://cdn.buct-alcp.top/20230906101832.png" alt="原始权重"></p>
<p>reorder后的权重weight_conv[LAYER_NUM]：</p>
<p><img src="https://cdn.buct-alcp.top/20230906102646.png" alt=""></p>
<p>放大图：</p>
<p><img src="https://cdn.buct-alcp.top/20230906102747.png" alt=""></p>
<p><img src="https://cdn.buct-alcp.top/20230906102831.png" alt=""></p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderWeights</span><span class="params">(DTYPE *weights, DTYPE *weight_buf, <span class="type">unsigned</span> dim1, <span class="type">unsigned</span> dim2, <span class="type">unsigned</span> dim3, <span class="type">unsigned</span> dim4, <span class="type">unsigned</span> dim3_original, <span class="type">unsigned</span> dim4_original, <span class="type">unsigned</span> offset, <span class="type">unsigned</span> padding_offset, <span class="type">unsigned</span> vecSize, <span class="type">unsigned</span> laneNum)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">	DTYPE    *copy_with_padding;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// First, copy the data into new buffer and padding in dim3/dim4 with zeros if needed</span></span><br><span class="line">	copy_with_padding  = (DTYPE *)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(DTYPE)*dim1*dim2*dim3*dim4);</span><br><span class="line">	<span class="keyword">if</span>(copy_with_padding == <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Error: not enough memory when padding weight!!!&quot;</span>);</span><br><span class="line">		<span class="built_in">free</span>(copy_with_padding);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">memset</span>(copy_with_padding, <span class="number">0</span>, <span class="built_in">sizeof</span>(DTYPE)*dim1*dim2*dim3*dim4);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> m = <span class="number">0</span>; m&lt;dim4_original; m++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> n = <span class="number">0</span>; n&lt;dim3_original; n++)&#123;</span><br><span class="line">			<span class="keyword">for</span>(<span class="type">unsigned</span> i = <span class="number">0</span>; i&lt;dim2; i++)&#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j&lt;dim1; j++)&#123;</span><br><span class="line">							copy_with_padding[(padding_offset*dim1*dim2*dim3) + m*dim1*dim2*dim3 + n*dim1*dim2 + i*dim1 + j]</span><br><span class="line">													= (DTYPE) weights[offset+m*dim1*dim2*dim3_original + n*dim1*dim2 + i*dim1 + j];</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Second, perform vectorization in dim3 by VEC_SIZE and at the same time, perform vectorization in dim4 by a factor of LANE_NUM</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> m = <span class="number">0</span>; m&lt;(dim4/laneNum); m++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> n = <span class="number">0</span>; n&lt;(dim3/vecSize); n++)&#123;</span><br><span class="line">			<span class="keyword">for</span>(<span class="type">unsigned</span> i = <span class="number">0</span>; i&lt;dim2; i++)&#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j&lt;dim1; j++)&#123;</span><br><span class="line">					<span class="keyword">for</span>(<span class="type">unsigned</span> ll = <span class="number">0</span>; ll&lt;laneNum; ll++)&#123;</span><br><span class="line">						<span class="keyword">for</span>(<span class="type">unsigned</span> k = <span class="number">0</span>; k&lt;vecSize; k++)&#123;</span><br><span class="line">							weight_buf[m*dim1*dim2*dim3*laneNum + n*dim1*dim2*vecSize*laneNum + i*dim1*vecSize*laneNum + j*vecSize*laneNum + ll*vecSize + k]</span><br><span class="line">													= (DTYPE) copy_with_padding[(m*laneNum+ll)*dim3*dim2*dim1 + (n*vecSize+k)*dim1*dim2 + i*dim1 + j];</span><br><span class="line">						&#125;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// release resource</span></span><br><span class="line">	<span class="built_in">free</span>(copy_with_padding);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h6 id="reorderBias"><strong>reorderBias()</strong></h6>
<p><strong>地址映射如下：</strong></p>
<blockquote>
<p>假设LANE_NUM = 4, dim4 =32</p>
<p>原始偏置：0-31的一维序列。</p>
<p>reorder后的偏置bias_conv[LAYER_NUM]：</p>
<p><img src="https://cdn.buct-alcp.top/20230906104811.png" alt=""></p>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">reorderBias</span><span class="params">(DTYPE *dataIn, DTYPE *bias, <span class="type">unsigned</span> offset, <span class="type">unsigned</span> padding_offset, <span class="type">unsigned</span> dim4, <span class="type">unsigned</span> dim4_original, <span class="type">unsigned</span> laneNum)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">	DTYPE *copy_with_padding;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// first copy the data into new buffer with zero paddings</span></span><br><span class="line">	copy_with_padding  = (DTYPE *)<span class="built_in">malloc</span>(<span class="built_in">sizeof</span>(DTYPE)*dim4);</span><br><span class="line">	<span class="keyword">if</span>(copy_with_padding == <span class="literal">NULL</span>)</span><br><span class="line">	&#123;</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Not enough memory when reordering bias!!!&quot;</span>);</span><br><span class="line">		<span class="built_in">free</span>(copy_with_padding);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="built_in">memset</span>(copy_with_padding, <span class="number">0</span>, <span class="built_in">sizeof</span>(DTYPE)*dim4);</span><br><span class="line">	<span class="comment">// padding evenly on two sides of weight_m</span></span><br><span class="line">	<span class="built_in">memcpy</span>(copy_with_padding+padding_offset, dataIn+offset, <span class="built_in">sizeof</span>(DTYPE)*dim4_original);</span><br><span class="line">	<span class="comment">// second, perform vectorization by factor of LANE_NUM</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> m = <span class="number">0</span>; m&lt;(dim4/laneNum); m++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> ll = <span class="number">0</span>; ll&lt;laneNum; ll++)&#123;</span><br><span class="line">			bias[m*laneNum + ll] = (DTYPE) copy_with_padding[m*laneNum + ll];</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="comment">// release resource</span></span><br><span class="line">	<span class="built_in">free</span>(copy_with_padding);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="⑧-创建命令队列、内核">⑧ 创建命令队列、内核</h4>
<p><strong>注意：⑧以及之后所以代码中“i”为第i个设备，由于设备数为1，所以i = 0。</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Command queue</span></span><br><span class="line">que_memRd[i] = <span class="built_in">clCreateCommandQueue</span>(context, device[device_ptr], CL_QUEUE_PROFILING_ENABLE, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create command queue 0&quot;</span>);</span><br><span class="line">que_conv[i] = <span class="built_in">clCreateCommandQueue</span>(context, device[device_ptr], CL_QUEUE_PROFILING_ENABLE, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create command queue 1&quot;</span>);</span><br><span class="line">que_memWr[i] = <span class="built_in">clCreateCommandQueue</span>(context, device[device_ptr], CL_QUEUE_PROFILING_ENABLE, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create command queue 2&quot;</span>);</span><br><span class="line">que_pool[i] = <span class="built_in">clCreateCommandQueue</span>(context, device[device_ptr], CL_QUEUE_PROFILING_ENABLE, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create command queue 3&quot;</span>);</span><br><span class="line">que_lrn[i] = <span class="built_in">clCreateCommandQueue</span>(context, device[device_ptr], CL_QUEUE_PROFILING_ENABLE, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create command queue 3&quot;</span>);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Kernel</span></span><br><span class="line">knl_memRd[i] = <span class="built_in">clCreateKernel</span>(program, knl_name_memRd, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create memRd kernel&quot;</span>);</span><br><span class="line"></span><br><span class="line">knl_conv[i] = <span class="built_in">clCreateKernel</span>(program, knl_name_conv, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create conv kernel&quot;</span>);</span><br><span class="line"></span><br><span class="line">knl_pool[i] = <span class="built_in">clCreateKernel</span>(program, knl_name_Pool, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create pooling kernel&quot;</span>);</span><br><span class="line"></span><br><span class="line">knl_memWr[i] = <span class="built_in">clCreateKernel</span>(program, knl_name_memWr, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create memWr kernel&quot;</span>);</span><br><span class="line"></span><br><span class="line">knl_lrn[i] = <span class="built_in">clCreateKernel</span>(program, knl_name_lrn, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create lrn kernel&quot;</span>);</span><br></pre></td></tr></table></figure>
<h4 id="⑨-创建FPGA缓冲区">⑨ 创建FPGA缓冲区</h4>
<h5 id="Ⅰ、创建weights、bias缓冲区">Ⅰ、创建weights、bias缓冲区</h5>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create weight and bias buffers for each layer</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j &lt; LAYER_NUM; ++j)&#123;</span><br><span class="line">    		weight_buf_size = layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config[j][weight_n]*layer_config[j][weight_m];</span><br><span class="line">			<span class="comment">// IntelFPGA</span></span><br><span class="line">			<span class="comment">// Weights buffers for each layer</span></span><br><span class="line">			weights_buf[i*LAYER_NUM+j] = <span class="built_in">clCreateBuffer</span>(context, CL_MEM_READ_ONLY, weight_buf_size* <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for weights in layer&quot;</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Bias buffers for each layer</span></span><br><span class="line">			bias_buf[i*LAYER_NUM+j] = <span class="built_in">clCreateBuffer</span>(context, CL_MEM_READ_ONLY, layer_config[j][bias_size] * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for bias in layer&quot;</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Initializing all weights buffers, blocking write is used</span></span><br><span class="line">			status = <span class="built_in">clEnqueueWriteBuffer</span>(que_memRd[i], weights_buf[i*LAYER_NUM+j], CL_TRUE, <span class="number">0</span>, weight_buf_size*<span class="built_in">sizeof</span>(DTYPE), weight_conv[j], <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to transfer weight&quot;</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clEnqueueWriteBuffer</span>(que_memRd[i], bias_buf[i*LAYER_NUM+j], CL_TRUE, <span class="number">0</span>, layer_config[j][bias_size] * <span class="built_in">sizeof</span>(DTYPE), bias_conv[j], <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to transfer bias&quot;</span>);</span><br><span class="line">&#125;</span><br><span class="line">		<span class="comment">// Wait for all data are send to FPGA</span></span><br><span class="line">		<span class="built_in">clFinish</span>(que_memRd[<span class="number">0</span>])</span><br></pre></td></tr></table></figure>
<ol>
<li><code>weights_buf[i*LAYER_NUM+j] = clCreateBuffer(context, CL_MEM_READ_ONLY, weight_buf_size * sizeof(DTYPE), NULL, &amp;status);</code>：
<ul>
<li><code>weights_buf</code> 是一个用于存储权重数据的缓冲区数组，索引 <code>i*LAYER_NUM+j</code> 表示第 <code>i</code> 个设备上的第 <code>j</code> 层神经网络的权重缓冲区。</li>
<li><code>clCreateBuffer</code> 是OpenCL函数，用于创建一个用于FPGA计算的缓冲区。</li>
<li><code>context</code> 是OpenCL上下文，用于管理计算资源。</li>
<li><code>CL_MEM_READ_ONLY</code> 表示该缓冲区只读，这意味着在FPGA计算过程中不会修改权重数据。</li>
<li><code>weight_buf_size * sizeof(DTYPE)</code> 是缓冲区的大小，以字节为单位，<code>weight_buf_size</code> 可能是权重数据的大小，而 <code>sizeof(DTYPE)</code> 是数据类型 <code>DTYPE</code> 的大小。</li>
<li><code>&amp;status</code> 是用于接收操作状态的变量的指针。</li>
</ul>
</li>
<li><code>status = clEnqueueWriteBuffer(que_memRd[i], weights_buf[i*LAYER_NUM+j], CL_TRUE, 0, weight_buf_size * sizeof(DTYPE), weight_conv[j], 0, NULL, NULL);</code>：
<ul>
<li><code>clEnqueueWriteBuffer</code> 是OpenCL函数，<strong>用于将数据从主机内存传输到FPGA缓冲区</strong>。</li>
<li><code>que_memRd[i]</code> 是第 <code>i</code> 个设备的命令队列，用于提交FPGA计算任务。</li>
<li><code>weights_buf[i*LAYER_NUM+j]</code> 是目标缓冲区，它是前面创建的用于存储权重的缓冲区。</li>
<li><code>CL_TRUE</code> 表示等待传输操作完成，这将使主机代码在数据传输完成之前被阻塞。</li>
<li><code>0</code> 是目标缓冲区的偏移量，通常设置为0，表示从缓冲区的起始位置开始写入数据。</li>
<li><code>weight_buf_size * sizeof(DTYPE)</code> 是要传输的数据大小，以字节为单位。</li>
<li><code>weight_conv[j]</code> 是源数据的指针，即reorder后的权重数据。</li>
<li>最后两个 <code>NULL</code> 参数用于设置事件对象，通常不使用，所以设置为 <code>NULL</code>。</li>
</ul>
</li>
</ol>
<p>总的来说，这段代码的作用是在OpenCL中创建用于存储神经网络权重的缓冲区，并将权重数据从主机内存传输到FPGA缓冲区中，以便后续的FPGA计算可以使用这些权重数据。</p>
<h5 id="Ⅱ、创建数据缓冲区">Ⅱ、创建数据缓冲区</h5>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Create data buffers for each batch item</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j &lt; input_config[batch_size]; ++j)&#123;</span><br><span class="line">			<span class="comment">// Input data buffers</span></span><br><span class="line">			data_buf[i*input_config[batch_size]+j] = <span class="built_in">clCreateBuffer</span>(context, CL_MEM_READ_WRITE, IN_BUF_SIZE * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for data in layer&quot;</span>);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// Output results buffers</span></span><br><span class="line">			output_buf[i*input_config[batch_size]+j] = <span class="built_in">clCreateBuffer</span>(context, CL_MEM_READ_WRITE, OUT_BUF_SIZE * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for output&quot;</span>);</span><br><span class="line">			</span><br><span class="line">			<span class="comment">// pool_buffer</span></span><br><span class="line">			pool_buf[i*input_config[batch_size]+j] = <span class="built_in">clCreateBuffer</span>(context, CL_MEM_READ_WRITE, POOL_BUF_SIZE * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for pool_buffer&quot;</span>);    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>其中data_buf和output_buf构成一对ping-pong buffer。</li>
</ul>
<h5 id="Ⅲ、创建全连接层缓冲区">Ⅲ、创建全连接层缓冲区</h5>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Allocate fc buffers</span></span><br><span class="line">fc_1_buf[i] = <span class="built_in">clCreateBuffer</span>(context,  CL_MEM_READ_WRITE, FC_BUF_SIZE * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for data in fc layer&quot;</span>);</span><br><span class="line"></span><br><span class="line">fc_2_buf[i] = <span class="built_in">clCreateBuffer</span>(context,  CL_MEM_READ_WRITE, FC_BUF_SIZE * <span class="built_in">sizeof</span>(DTYPE), <span class="literal">NULL</span>, &amp;status);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to create buffer for data in fc layer&quot;</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li>fc_1_buf与fc_2_buf一对ping-pong buffer。</li>
</ul>
<h4 id="⑩-执行内核">⑩ 执行内核</h4>
<p>这里以ALEXNET为例来演示内核的执行。由于当时GPU内存的限制引起的，作者使用两块GPU进行计算，因此分为了上下两部分，而PipeCNN也提供了<strong>conv_split</strong> 参数用于实现最原始的ALEXNET，结构如下图所示。</p>
<p><strong>值得注意的一点：原图输入224 × 224，实际上进行了随机裁剪，实际大小为227 × 227。</strong></p>
<p><img src="https://img-blog.csdnimg.cn/20210707180001313.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d1emhhbzk5MDE=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p>
<h5 id="Ⅰ、loadImageToBuffer-函数">Ⅰ、loadImageToBuffer()函数</h5>
<p>第一步，从input_file_path中读取图片image.dat到全局变量image中。</p>
<p>第二步，将image向量化并写入data_init中。</p>
<p><strong>地址映射如下：</strong></p>
<blockquote>
<p>假设VEC_SIZE = 8, data_w = data_h =224, data_n = 3，实际上输入图像应该为227*227*3，这里意会就好。</p>
<p><img src="https://cdn.buct-alcp.top/20230906144640.png" alt=""></p>
<img src="https://cdn.buct-alcp.top/20230906144702.png" style="zoom:80%;" />
<p>其中：</p>
<ul>
<li>data_init[0] = image[0]</li>
<li>data_init[1] = image[50176]</li>
<li>data_init[2] = image[100352]</li>
<li>data_init[8] = image[1]</li>
</ul>
</blockquote>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">loadImageToBuffer</span><span class="params">(<span class="type">int</span> num)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">	cl_int status;</span><br><span class="line">	ifstream bin_file_r;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Image</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> USE_OPENCV</span></span><br><span class="line">	<span class="comment">// load image from picture files</span></span><br><span class="line">	<span class="comment">// get the correct paths for each pictures</span></span><br><span class="line">	<span class="type">char</span> end[<span class="number">14</span>]=<span class="string">&quot;00000000.JPEG&quot;</span>;<span class="comment">//endof the char[] &#x27;\0&#x27;</span></span><br><span class="line">	<span class="type">char</span> head[<span class="number">100</span>];</span><br><span class="line">	<span class="built_in">numtochar</span>(num,end);</span><br><span class="line">	<span class="built_in">memset</span>(picture_file_path,<span class="number">0x00</span>,<span class="built_in">sizeof</span>(<span class="type">char</span>)*<span class="number">100</span>);</span><br><span class="line">	<span class="built_in">strcpy</span>(head,picture_file_path_head);</span><br><span class="line">	<span class="built_in">strcpy</span>(picture_file_path,<span class="built_in">strcat</span>(head,end));</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(<span class="built_in">load_picture</span>(image)==<span class="number">1</span>)</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Error: loading image data from real pictures failed !!!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">	<span class="type">unsigned</span> file_size;</span><br><span class="line">	<span class="comment">// load image from binary files</span></span><br><span class="line">	bin_file_r.<span class="built_in">open</span>(input_file_path, ios::in | ios::binary);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(bin_file_r.<span class="built_in">is_open</span>())</span><br><span class="line">    &#123;</span><br><span class="line">		<span class="comment">//Get file size</span></span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.end);</span><br><span class="line">		file_size = bin_file_r.<span class="built_in">tellg</span>();</span><br><span class="line">		bin_file_r.<span class="built_in">seekg</span>(<span class="number">0</span>, bin_file_r.beg);</span><br><span class="line"></span><br><span class="line">		bin_file_r.<span class="built_in">read</span>((<span class="type">char</span> *)image, <span class="built_in">sizeof</span>(DTYPE)*IMAGE_FILE_SIZE);</span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;\n%d bytes image data read from binary files\n&quot;</span>, file_size);</span><br><span class="line">		<span class="keyword">if</span>(IMAGE_FILE_SIZE!=(file_size/(<span class="built_in">sizeof</span>(DTYPE))))</span><br><span class="line">			<span class="built_in">printf</span>(<span class="string">&quot;Warning: image file size does not match user configuration !!!\n&quot;</span>);</span><br><span class="line">		bin_file_r.<span class="built_in">close</span>();</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;Image file does not exits !!!\n&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// Vectorize the input image by a factor of VEC_SIZE</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> n = <span class="number">0</span>; n&lt;layer_config[<span class="number">0</span>][data_n]/VEC_SIZE; n++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> i = <span class="number">0</span>; i&lt;layer_config[<span class="number">0</span>][data_h]; i++)&#123;</span><br><span class="line">			<span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j&lt;layer_config[<span class="number">0</span>][data_w]; j++)&#123;</span><br><span class="line">				<span class="keyword">for</span>(<span class="type">unsigned</span> k = <span class="number">0</span>; k&lt;VEC_SIZE; k++)&#123;</span><br><span class="line">					<span class="keyword">if</span>((n*VEC_SIZE+k)&lt;layer_config_original[<span class="number">0</span>][data_n])&#123; <span class="comment">//  when layer_config[0][data_n] &gt; layer_config_original[0][data_n], only copy valid pixels</span></span><br><span class="line">						data_init[n*VEC_SIZE*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_w] + i*layer_config[<span class="number">0</span>][data_w]*VEC_SIZE + j*VEC_SIZE + k]</span><br><span class="line">							= (DTYPE) image[(n*VEC_SIZE+k)*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_w] + i*layer_config[<span class="number">0</span>][data_w] + j];</span><br><span class="line">					&#125;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> i = <span class="number">0</span>; i &lt; num_devices; ++i) &#123;</span><br><span class="line">		<span class="comment">// Create data buffers for each batch item</span></span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> j = <span class="number">0</span>; j &lt; input_config[batch_size]; ++j)&#123;</span><br><span class="line"><span class="meta">#<span class="keyword">if</span> defined(USE_SDX_1DDR)</span></span><br><span class="line">			<span class="built_in">clEnqueueMigrateMemObjects</span>(que_memRd[i],<span class="number">1</span>, &amp;data_buf[i*input_config[batch_size]+j], <span class="number">0</span> <span class="comment">/* flags, 0 means from host*/</span>,<span class="number">0</span>, <span class="literal">NULL</span>,&amp;write_event[i]);</span><br><span class="line"><span class="meta">#<span class="keyword">elif</span> defined(USE_SDX_4DDR)</span></span><br><span class="line">			<span class="comment">// Load image data into buffers</span></span><br><span class="line">			status = <span class="built_in">clEnqueueWriteBuffer</span>(que_memRd[i], data_buf[i*input_config[batch_size]+j], CL_TRUE, <span class="number">0</span>, (layer_config[<span class="number">0</span>][data_w]*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_n]) * <span class="built_in">sizeof</span>(DTYPE), data_init, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to transfer input image&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">			<span class="comment">// Load image data into buffers</span></span><br><span class="line">			status = <span class="built_in">clEnqueueWriteBuffer</span>(que_memRd[i], data_buf[i*input_config[batch_size]+j], CL_TRUE, <span class="number">0</span>, (layer_config[<span class="number">0</span>][data_w]*layer_config[<span class="number">0</span>][data_h]*layer_config[<span class="number">0</span>][data_n]) * <span class="built_in">sizeof</span>(DTYPE), data_init, <span class="number">0</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to transfer input image&quot;</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅱ、-网络的执行步骤说明">Ⅱ、*网络的执行步骤说明</h5>
<p>PipeCNN将DCNN中的每一层通过以下结构实现：</p>
<p><strong>MemRd -&gt; Conv(Relu) -&gt; (MaxPool) -&gt; MemWr -&gt; (Lrn)</strong>，Lrn: Local Response Normalization</p>
<p><img src="https://cdn.buct-alcp.top/20230906151749.png" alt=""></p>
<h5 id="Ⅲ、计算并配置MemRd输入参数">Ⅲ、计算并配置MemRd输入参数</h5>
<p><strong>计算：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Convolution tasks (conv_x,conv_y) are divided into multiple groups</span></span><br><span class="line"><span class="comment">// each group process CONV_GP_SIZE_X*CONV_GP_SIZE_Y convolutions in parallel</span></span><br><span class="line">conv_group_num_dim1   = <span class="built_in">ceil</span>((<span class="type">float</span>)layer_config[j][conv_x]/CONV_GP_SIZE_X);</span><br><span class="line">conv_group_num_dim2   = <span class="built_in">ceil</span>((<span class="type">float</span>)layer_config[j][conv_y]/CONV_GP_SIZE_Y);</span><br><span class="line"><span class="keyword">if</span>(layer_config[j][conv_x]==<span class="number">1</span>)&#123; <span class="comment">// when only one group for FC layer</span></span><br><span class="line">	conv_win_size_dim1  = layer_config[j][weight_w];</span><br><span class="line">	conv_group_rem_dim1   = layer_config[j][weight_w];</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">	conv_win_size_dim1  = layer_config[j][weight_w]+(CONV_GP_SIZE_X<span class="number">-1</span>)*layer_config[j][conv_stride];</span><br><span class="line">	<span class="comment">// actual number of input pixels need to be read in the last group according to the number of the remaining valid conv items in the last group</span></span><br><span class="line">	<span class="comment">// the remaining valid conv items is layer_config[j][conv_x]%CONV_GP_SIZE_X</span></span><br><span class="line">	<span class="keyword">if</span>(layer_config[j][conv_x]%CONV_GP_SIZE_X==<span class="number">0</span>)</span><br><span class="line">		conv_group_rem_dim1   = CONV_GP_SIZE_X*layer_config[j][weight_w];</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		conv_group_rem_dim1   = layer_config[j][conv_x]%CONV_GP_SIZE_X*layer_config[j][weight_w];</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// In this version, grouping is not performed in the column (y) direction, i.e., CONV_GP_SIZE_Y=1</span></span><br><span class="line">conv_win_size_dim2    = layer_config[j][weight_h];</span><br><span class="line">conv_group_rem_dim2   = layer_config[j][weight_h];</span><br><span class="line">conv_win_size_dim1x2x3  = conv_win_size_dim1*conv_win_size_dim2*layer_config[j][weight_n];</span><br><span class="line">conv_group_rem_dim1x2x3 = conv_group_rem_dim1*conv_group_rem_dim2*layer_config[j][weight_n];</span><br><span class="line"></span><br><span class="line">weight_dim4_div_LaneNum = layer_config[j][weight_m]/LANE_NUM;</span><br><span class="line">data_dim1x2 = layer_config[j][data_w]*layer_config[j][data_h];</span><br><span class="line">weight_dim1x2 = layer_config[j][weight_w]*layer_config[j][weight_h];</span><br><span class="line">weight_dim1x2x3 = layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config[j][weight_n];</span><br></pre></td></tr></table></figure>
<p>ALEXNET第一层参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_w, data_h, data_n = 227, 227, 8(padding)</span><br><span class="line">weight_w, weight_h, weight_n, weight_m = 11, 11, 8(padding) ,96</span><br><span class="line">conv_x, conv_y = 55, 55</span><br><span class="line">conv_stride = 4</span><br></pre></td></tr></table></figure>
<p>MemRd输入参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 一个卷积的group size，hw_param.cl中定义</span><br><span class="line">CONV_GP_SIZE_X, CONV_GP_SIZE_Y = 7, 1</span><br><span class="line"></span><br><span class="line">// group数量</span><br><span class="line">conv_group_num_dim1 = ceil(55/7) = 8	</span><br><span class="line">conv_group_num_dim2 = ceil(55/1) = 55</span><br><span class="line"></span><br><span class="line">// conv层窗口（提高带宽）</span><br><span class="line">conv_win_size_dim1 = 11 + (7-1)*4 = 35</span><br><span class="line">conv_group_rem_dim1 = (55%7)*11 = 66</span><br><span class="line">conv_win_size_dim2 = 11</span><br><span class="line">conv_group_rem_dim2 = 11</span><br><span class="line">conv_win_size_dim1x2x3 = 35*11*8</span><br><span class="line">conv_group_rem_dim1x2x3 = 66*11*8 </span><br><span class="line"></span><br><span class="line">// </span><br><span class="line">weight_dim4_div_LaneNum = 96/4 = 24</span><br><span class="line">data_dim1x2 = 227*227</span><br><span class="line">weight_dim1x2 = 11*11</span><br><span class="line">weight_dim1x2x3 = 11*11*8</span><br></pre></td></tr></table></figure>
<p><strong>配置：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][data_w]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][data_h]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_ushort), &amp;data_dim1x2);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][weight_w]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][weight_h]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_ushort), &amp;layer_config[j][weight_n]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_ushort), &amp;weight_dim4_div_LaneNum);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;weight_dim1x2);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uint),  &amp;weight_dim1x2x3);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][conv_x]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//status = clSetKernelArg(knl_memRd[i], argi++, sizeof(cl_uchar), &amp;layer_config[j][conv_y]);</span></span><br><span class="line"><span class="comment">//checkError(status, &quot;Failed to set argument %d of kernel memRd&quot;, argi - 1);</span></span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][conv_stride]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][conv_padding]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;layer_config[j][conv_split]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;conv_group_num_dim1);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;conv_group_num_dim2);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;conv_group_rem_dim1);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//status = clSetKernelArg(knl_memRd[i], argi++, sizeof(cl_uchar), &amp;conv_group_rem_dim2);</span></span><br><span class="line"><span class="comment">//checkError(status, &quot;Failed to set argument %d of kernel memRd&quot;, argi - 1);</span></span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uint), &amp;conv_group_rem_dim1x2x3);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;conv_win_size_dim1);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uchar), &amp;conv_win_size_dim2);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_uint), &amp;conv_win_size_dim1x2x3);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h5 id="Ⅳ、配置MemRd输入数据来源">Ⅳ、配置MemRd输入数据来源</h5>
<p><strong>数据来源：data_buf、output_buf、fc_1_buf、fc_2_buf、poolbuf</strong></p>
<p>ALEXNET所有层连接参考：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">data_buf -&gt; conv1 -&gt; output_buf -&gt; pooling1 -&gt; poolbuf -&gt; lrn1 -&gt;</span><br><span class="line">data_buf -&gt; conv2 -&gt; output_buf -&gt; pooling2 -&gt; poolbuf -&gt; lrn2 -&gt;</span><br><span class="line">data_buf -&gt; conv3 -&gt;</span><br><span class="line">output_buf -&gt; conv4 -&gt;</span><br><span class="line">data_buf -&gt; conv5 -&gt; output_buf -&gt; pooling3 -&gt; </span><br><span class="line">poolbuf -&gt; fc1 -&gt;</span><br><span class="line">fc_1_buf -&gt; fc2 -&gt;</span><br><span class="line">fc_2_buf -&gt; fc3 -&gt; fc_1_buf</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Select the kernel input mem object source</span></span><br><span class="line"><span class="comment">// data_buf -&gt; conv1 -&gt; output_buf -&gt; lrn1 -&gt; data_buf -&gt; conv2 -&gt; output_buf -&gt; lrn2 -&gt; data_buf</span></span><br><span class="line"><span class="comment">// -&gt; conv3 -&gt; output_buf -&gt; conv4 -&gt; output_buf -&gt; ...</span></span><br><span class="line"><span class="keyword">if</span>(layer_config[j][memrd_src]==<span class="number">0</span>)&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;data_buf[i*input_config[batch_size]+k]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(layer_config[j][memrd_src]==<span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;output_buf[i*input_config[batch_size]+k]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(layer_config[j][memrd_src]==<span class="number">2</span>)</span><br><span class="line">&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;fc_1_buf[i]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(layer_config[j][memrd_src]==<span class="number">3</span>)</span><br><span class="line">&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;fc_2_buf[i]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(layer_config[j][memrd_src] ==<span class="number">4</span>)</span><br><span class="line">&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;pool_buf[i*input_config[batch_size]+k]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line"><span class="keyword">else</span> <span class="comment">// 5</span></span><br><span class="line">&#123;</span><br><span class="line">	status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;eltwise_buf[i*input_config[batch_size]+k]);</span><br><span class="line">	<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;weights_buf[i*LAYER_NUM+j]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">status = <span class="built_in">clSetKernelArg</span>(knl_memRd[i], argi++, <span class="built_in">sizeof</span>(cl_mem), &amp;bias_buf[i*LAYER_NUM+j]);</span><br><span class="line"><span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d kernel memRd&quot;</span>, argi - <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h5 id="Ⅴ、配置CONV-输入参数-883-907">Ⅴ、配置CONV 输入参数(883-907)</h5>
<p>ALEXNET第一层参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data_w, data_h, data_n = 227, 227, 8(padding)</span><br><span class="line">weight_w, weight_h, weight_n, weight_m = 11, 11, 8(padding) ,96</span><br><span class="line">conv_x, conv_y = 55, 55</span><br><span class="line">conv_stride = 4</span><br></pre></td></tr></table></figure>
<p>CONV输入参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">// 生成输出特征图的循环次数</span><br><span class="line">conv_output_num = conv_x * conv_y * weight_m/LANE_NUM = 55 * 55 * 96/4</span><br><span class="line">// 计算单个向量卷积核的循环次数，LANE_NUM路并行</span><br><span class="line">conv_loop_cnt = weight_w * weight_h * weight_n/VEC_SIZE = 11 * 11 * 8/8</span><br><span class="line">//卷积控制字：该卷积核是否要激活、通过maxpooling层</span><br><span class="line">conv_control = (layer_config[j][conv_relu]&amp;0x01)|(((~layer_config[j][pool_on])&amp;0x01)&lt;&lt;1);</span><br><span class="line">// 精度控制字：需要设计</span><br><span class="line">frac_w = 8</span><br><span class="line">frac_din = 0</span><br><span class="line">frac_dout = -4</span><br></pre></td></tr></table></figure>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">			conv_loop_cnt = layer_config[j][weight_w]*layer_config[j][weight_h]*layer_config[j][weight_n]/VEC_SIZE;</span><br><span class="line">			conv_output_num = layer_config[j][conv_x]*layer_config[j][conv_y]*layer_config[j][weight_m]/LANE_NUM; <span class="comment">// new weight_m is divisible by LANE_NUM</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">			conv_control = layer_config[j][layer_type];</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">			conv_control = (layer_config[j][conv_relu]&amp;<span class="number">0x01</span>)|(((~layer_config[j][pool_on])&amp;<span class="number">0x01</span>)&lt;&lt;<span class="number">1</span>);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_uint), &amp;conv_output_num);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_uint), &amp;conv_loop_cnt);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_uint), &amp;conv_control);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_char), &amp;precision_config[j][frac_w]);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_char), &amp;precision_config[j][frac_din]);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">			status = <span class="built_in">clSetKernelArg</span>(knl_conv[i], argi++, <span class="built_in">sizeof</span>(cl_char), &amp;precision_config[j][frac_dout]);</span><br><span class="line">			<span class="built_in">checkError</span>(status, <span class="string">&quot;Failed to set argument %d of kernel conv&quot;</span>, argi - <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<h2 id="三、kernel代码">三、kernel代码</h2>
<h3 id="3-1-数据类型说明">3.1 数据类型说明</h3>
<ul>
<li>
<p>MACTYPE：int型，32bit</p>
</li>
<li>
<p>DPTYPE：char型，8bit</p>
</li>
<li>
<p>lane_data：每个lane的向量化数据</p>
<p><img src="https://cdn.buct-alcp.top/20230906170010.png" alt=""></p>
</li>
<li>
<p>channel_vec：</p>
<p><img src="https://cdn.buct-alcp.top/20230906170050.png" alt=""></p>
</li>
<li>
<p>channel_scal：</p>
<p><img src="https://cdn.buct-alcp.top/20230906170108.png" alt=""></p>
</li>
<li>
<p>channel_scal_float：</p>
<p><img src="https://cdn.buct-alcp.top/20230906170122.png" alt=""></p>
</li>
</ul>
<h3 id="3-2-滑动窗与卷积过程">3.2 滑动窗与卷积过程</h3>
<p>MemRd输入参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">// 一个卷积的group size，hw_param.cl中定义</span><br><span class="line">CONV_GP_SIZE_X, CONV_GP_SIZE_Y = 7, 1</span><br><span class="line"></span><br><span class="line">// group数</span><br><span class="line">conv_group_num_dim1 = ceil(55/7) = 8	</span><br><span class="line">conv_group_num_dim2 = ceil(55/1) = 55</span><br><span class="line"></span><br><span class="line">// conv层窗口</span><br><span class="line">conv_win_size_dim1 = 11 + (7-1)*4 = 35</span><br><span class="line">conv_group_rem_dim1 = (55%7)*11 = 66	// dim1最后一个group读取的像素总数</span><br><span class="line">conv_win_size_dim2 = 11</span><br><span class="line">conv_group_rem_dim2 = 11</span><br><span class="line">conv_win_size_dim1x2x3 = 35*11*8</span><br><span class="line">conv_group_rem_dim1x2x3 = 66*11*8 </span><br><span class="line"></span><br><span class="line">// 其他</span><br><span class="line">weight_dim4_div_LaneNum = 96/4 = 24</span><br><span class="line">data_dim1x2 = 227*227</span><br><span class="line">weight_dim1x2 = 11*11</span><br><span class="line">weight_dim1x2x3 = 11*11*8</span><br></pre></td></tr></table></figure>
<h4 id="①-滑动窗结构示意图">① 滑动窗结构示意图</h4>
<p><img src="https://cdn.buct-alcp.top/20230906171944.png" alt=""></p>
<h4 id="②-group与item">② group与item</h4>
<ul>
<li>
<p>1个滑动窗就是1个group，conv_group_num_dim1和conv_group_num_dim2代表输入特征图dim1和dim2的group数。</p>
</li>
<li>
<p><code>CONV_GP_SIZE_X * CONV_GP_SIZE_Y = 7</code>，代表1个group中包含7个item，每个group可以并行计算这7个item的卷积。</p>
</li>
</ul>
<p><img src="https://cdn.buct-alcp.top/20230906205146.png" alt=""></p>
<p>图中显示了一个35*11的滑动窗，包含7个item：0-10、4-14、8-18、12-22、16-26、20-30、24-34。</p>
<h4 id="③-滑动窗卷积过程">③ 滑动窗卷积过程</h4>
<ol>
<li>在dim1方向上，227*227的图片可以被分成8个group，相邻的group被分别送入win_buffer[0]和win_buffer[1]以实现流水线处理。</li>
<li>细节：
<ul>
<li>一共创建了<strong>LANE_NUM = 4</strong>条流水线，每条流水线使用1个卷积核处理同一个group，group中包含<strong>CONV_GP_SIZE_X * CONV_GP_SIZE_Y = 7</strong>个item。</li>
<li>每条流水线中，卷积核同时与7个item卷积（并行计算+weights reuse）。1条流水线可以生成输出特征图1个通道的7个点，4条流水线可以生成输出特征图4个通道的28个点。</li>
<li>最后经过<strong>weight_dim4_div_LaneNum = 24</strong> 次循环，96个通道全部计算完毕，生成了7*1*96的输出特征图，代表这个group就处理完了，紧接着处理下一个group。</li>
</ul>
</li>
</ol>
<p><img src="https://cdn.buct-alcp.top/20230906205718.png" alt=""></p>
<h3 id="3-3-conv-pipe-cl代码">3.3 conv_pipe.cl代码</h3>
<h4 id="①-memRead-kernel">① memRead kernel</h4>
<h5 id="〇、参数说明">〇、参数说明</h5>
<p><strong>计数器：</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 滑动窗内的计数器</span></span><br><span class="line">uchar  win_itm_x, win_itm_y;</span><br><span class="line">ushort win_itm_z;</span><br><span class="line"></span><br><span class="line"><span class="comment">// group loop计数器</span></span><br><span class="line">ushort gp_num_x, gp_num_y, out_idx_z;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 滑动窗所属的group loop计数器，out_idx_z_winbuf &lt;= weight_dim4_div_lane -1</span></span><br><span class="line">ushort gp_num_x_winbuf, gp_num_y_winbuf, out_idx_z_winbuf;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅰ、初始化第一个win-buffer-181-205">Ⅰ、初始化第一个win_buffer(181-205)</h5>
<p><img src="https://cdn.buct-alcp.top/20230906213455.png" alt=""></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Initialize the winbuf with the data in the first iteration of the group looping (as gp_num_x_winbuf=0, gp_num_y_winbuf=0)</span></span><br><span class="line"><span class="keyword">for</span>(win_itm_z=<span class="number">0</span>; win_itm_z&lt;weight_dim3/VEC_SIZE; win_itm_z++)&#123;</span><br><span class="line">	<span class="keyword">for</span>(win_itm_y=<span class="number">0</span>; win_itm_y&lt;win_size_y; win_itm_y++)&#123;</span><br><span class="line">		<span class="keyword">for</span>(win_itm_x=<span class="number">0</span>; win_itm_x&lt;win_size_x; win_itm_x++)&#123;</span><br><span class="line"></span><br><span class="line">		feature_idx_dim1 = win_itm_x;</span><br><span class="line">		feature_idx_dim2 = win_itm_y;</span><br><span class="line">		feature_idx_dim3 = win_itm_z;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// fetch feature map for the current group and caching in win buffer</span></span><br><span class="line">		<span class="keyword">if</span>((feature_idx_dim1&gt;=padding &amp;&amp; feature_idx_dim1&lt;data_dim1+padding) &amp;&amp; (feature_idx_dim2&gt;=padding &amp;&amp; feature_idx_dim2&lt;data_dim2+padding))&#123;</span><br><span class="line">			data_vec = bottom[data_offset*data_dim1xdim2 + feature_idx_dim3*data_dim1xdim2 + (feature_idx_dim2-padding)*data_dim1 + (feature_idx_dim1-padding)];</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">else</span>&#123; <span class="comment">// for padding (feature_idx&lt;padding or data_dim+padding&lt;=feature_idx&lt;data_dim+2*padding)</span></span><br><span class="line">			<span class="comment">// or invalid work-item in the last group set feature map to zeros (feature_idx&gt;=data_dim+2*padding)</span></span><br><span class="line">			<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">			<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> vv=<span class="number">0</span>; vv&lt;VEC_SIZE; vv++)&#123;</span><br><span class="line">				data_vec.data[vv] = CZERO;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="comment">// start from using buffer[0]</span></span><br><span class="line">		win_buffer[<span class="number">0</span>][win_itm_z*win_size_y*win_size_x + win_itm_y*win_size_x + win_itm_x] = data_vec;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line">win_itm_x = <span class="number">0</span>; win_itm_y = <span class="number">0</span>; win_itm_z = <span class="number">0</span>;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅱ、计算卷积参数-210-241">Ⅱ、计算卷积参数(210-241)</h5>
<ul>
<li>对于普通的卷积层，gp loop计数器gp_num_x_winbuf比global gp loop计数器gp_num_x提前一个滑动窗。</li>
<li>定义了重要的循环参数，这些循环参数是为了尽可能减少循环的嵌套以提高kernel的效率。
<ul>
<li><code>ItemLoopBound = weight_dim1x2x3 * CONV_GP_SIZE_Y * CONV_GP_SIZE_X / VEC_SIZE</code>，表示1个group内的循环次数。</li>
<li><code>ItemLastLoopBound</code>，表示每一行最后一个group的循环数。</li>
<li><code>TotalLoopBound</code>，表示整个特征图的循环数，由前二者算出来。</li>
</ul>
</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// reset group virtual loop counters for winbuf loading operations</span></span><br><span class="line"><span class="comment">// the gp loop counter for winbuf starts one iteration earlier than global group virtual loop counter</span></span><br><span class="line"><span class="comment">// in this iteration, the winbuf is pre-initialized as previous loops shows</span></span><br><span class="line"><span class="keyword">if</span>(group_num_x==<span class="number">1</span> &amp;&amp; group_num_y==<span class="number">1</span>)&#123;</span><br><span class="line">	gp_num_x_winbuf = <span class="number">0</span>; <span class="comment">// there is only one group for FC mode when batch=1</span></span><br><span class="line">	gp_num_y_winbuf = <span class="number">0</span>;&#125;</span><br><span class="line"><span class="keyword">else</span> <span class="keyword">if</span>(group_num_x==<span class="number">1</span>)&#123;</span><br><span class="line">	gp_num_x_winbuf = <span class="number">0</span>; <span class="comment">// special case for convolution layers with weight_dim1/2=1, such as resnet50</span></span><br><span class="line">	gp_num_y_winbuf = <span class="number">1</span>;&#125;</span><br><span class="line"><span class="keyword">else</span>&#123;</span><br><span class="line">	gp_num_x_winbuf = <span class="number">1</span>; <span class="comment">// loop start from the second group for normal convolution layers</span></span><br><span class="line">	gp_num_y_winbuf = <span class="number">0</span>;&#125;</span><br><span class="line"></span><br><span class="line">out_idx_z_winbuf = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// reset global group virtual loop counters</span></span><br><span class="line">gp_num_x = <span class="number">0</span>;           <span class="comment">// Which group in x dim</span></span><br><span class="line">gp_num_y = <span class="number">0</span>;           <span class="comment">// Which group in y dim</span></span><br><span class="line">out_idx_z = <span class="number">0</span>;          <span class="comment">// Which group in z dim</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// The &quot;Group&quot; and &quot;Item&quot; for loops are merged to improve pipeline efficiency.</span></span><br><span class="line">uint conv_x_idx = <span class="number">0</span>;    <span class="comment">// It is used to check the validation of the output pixel, conv_x_idx = gp_num_x*CONV_GP_SIZE_X+gp_item_idx_x, and it should within [0, conv_x]</span></span><br><span class="line">uint out_idx_xyz = <span class="number">0</span>;   <span class="comment">// Index of output groups, it indicates which output group.</span></span><br><span class="line">uint item_loop_cnt = <span class="number">0</span>; <span class="comment">// The counter to determine the end of one group.</span></span><br><span class="line">uint ItemLoopBound;     <span class="comment">// The loop tripcount within one group.</span></span><br><span class="line">uint ItemLastLoopBound; <span class="comment">// The loop tripcount of the last group of each conv_out row.</span></span><br><span class="line">uint TotalLoopBound;    <span class="comment">// Total loop tripcount for the entire feature map.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span>(stride&gt;=weight_dim1 || stride&gt;=weight_dim2) <span class="comment">// special case convolution layers with stride&gt;weight_dim1/2, such as resnet50</span></span><br><span class="line">	ItemLoopBound = win_size_xyz/VEC_SIZE;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">	ItemLoopBound = (weight_dim1x2x3*CONV_GP_SIZE_Y*CONV_GP_SIZE_X/VEC_SIZE);</span><br><span class="line">ItemLastLoopBound = win_size_x&gt;=group_rem_size_x?(win_size_xyz/VEC_SIZE):(group_rem_size_xyz/VEC_SIZE);</span><br><span class="line"></span><br><span class="line">TotalLoopBound = ((group_num_x<span class="number">-1</span>)*ItemLoopBound+ItemLastLoopBound) * group_num_y * weight_dim4_div_lane;</span><br></pre></td></tr></table></figure>
<p>最大的loop：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">int</span> total_cnt=<span class="number">0</span>; total_cnt&lt;TotalLoopBound; total_cnt++)&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅲ、装载一个新的group-250-315">Ⅲ、装载一个新的group(250-315)</h5>
<ul>
<li>flag用于将读取的滑动窗缓存到win_buffer[1]或[0]。</li>
<li><code>load_feature_flag = 1</code>表示可以装载数据。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(item_loop_cnt == <span class="number">0</span>)&#123;<span class="comment">// if starting from a new group.</span></span><br><span class="line">	<span class="comment">// special case when split==1, the output feature maps depend on only half the input feature maps</span></span><br><span class="line">	<span class="keyword">if</span>(split==<span class="number">0</span>)</span><br><span class="line">		data_offset = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>(out_idx_z_winbuf&lt;(weight_dim4_div_lane&gt;&gt;<span class="number">1</span>)) <span class="comment">// the lower half of the output feature maps depend on the lower half of the input</span></span><br><span class="line">		data_offset = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		data_offset = weight_dim3/VEC_SIZE;	<span class="comment">// the upper half of the output feature maps depend on the upper half of the input</span></span><br><span class="line"></span><br><span class="line">	flag = out_idx_xyz &amp; <span class="number">0x01</span>; <span class="comment">//ping-pong flag</span></span><br><span class="line">	load_feature_flag = <span class="number">1</span>;</span><br><span class="line">	<span class="keyword">if</span>(gp_num_x==group_num_x<span class="number">-1</span>) <span class="comment">// last group in each row</span></span><br><span class="line">		<span class="comment">// ensuring that both winbuf load loop and output loop are finished, i.e., use a larger value as the loop bound</span></span><br><span class="line">		item_loop_bound = ItemLastLoopBound;</span><br><span class="line">	<span class="keyword">else</span>&#123;</span><br><span class="line">		item_loop_bound = ItemLoopBound;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>现将bottem里的数据padding，存入data_vec变量中。</p>
</li>
<li>
<p>将data_vec的数据传入win_buffer中，直到1个group被装载完成，随后<code>load_feature_flag = 0</code></p>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(load_feature_flag==<span class="number">1</span>)&#123;</span><br><span class="line"></span><br><span class="line">	feature_idx_dim1 = win_itm_x+gp_num_x_winbuf*CONV_GP_SIZE_X*stride;</span><br><span class="line">	feature_idx_dim2 = win_itm_y+gp_num_y_winbuf*CONV_GP_SIZE_Y*stride;</span><br><span class="line">	feature_idx_dim3 = win_itm_z;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// fetch feature map for the current group and caching in win buffer</span></span><br><span class="line">	<span class="keyword">if</span>((feature_idx_dim1&gt;=padding &amp;&amp; feature_idx_dim1&lt;data_dim1+padding) &amp;&amp; (feature_idx_dim2&gt;=padding &amp;&amp; feature_idx_dim2&lt;data_dim2+padding))&#123;</span><br><span class="line">		data_vec = bottom[data_offset*data_dim1xdim2 + feature_idx_dim3*data_dim1xdim2 + (feature_idx_dim2-padding)*data_dim1 + (feature_idx_dim1-padding)];</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span>&#123; <span class="comment">// for padding (feature_idx&lt;padding or data_dim+padding&lt;=feature_idx&lt;data_dim+2*padding)</span></span><br><span class="line">		<span class="comment">// or invalid work-item in the last group set feature map to zeros (feature_idx&gt;=data_dim+2*padding)</span></span><br><span class="line">		<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> vv=<span class="number">0</span>; vv&lt;VEC_SIZE; vv++)&#123;</span><br><span class="line">			data_vec.data[vv] = CZERO;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	win_buffer[(~flag)&amp;<span class="number">0x01</span>][win_itm_z*win_size_y*win_size_x + win_itm_y*win_size_x + win_itm_x] = data_vec;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// used as loop counters</span></span><br><span class="line">	<span class="keyword">if</span>((win_itm_z==weight_dim3/VEC_SIZE<span class="number">-1</span>) &amp;&amp; (win_itm_y==win_size_y<span class="number">-1</span>) &amp;&amp; (win_itm_x==win_size_x<span class="number">-1</span>))&#123;</span><br><span class="line">		win_itm_z = <span class="number">0</span>;</span><br><span class="line">		load_feature_flag = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>((win_itm_y==win_size_y<span class="number">-1</span>) &amp;&amp; (win_itm_x==win_size_x<span class="number">-1</span>))&#123;</span><br><span class="line">		win_itm_z++;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>((win_itm_y==win_size_y<span class="number">-1</span>) &amp;&amp; (win_itm_x==win_size_x<span class="number">-1</span>))&#123;</span><br><span class="line">		win_itm_y = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>(win_itm_x==win_size_x<span class="number">-1</span>)</span><br><span class="line">		win_itm_y++;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(win_itm_x==win_size_x<span class="number">-1</span>)</span><br><span class="line">		win_itm_x = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		win_itm_x++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅳ、装载weight-buffer-318-321">Ⅳ、装载weight_buffer(318-321)</h5>
<ul>
<li>当<code>load_weight_flag = 1</code>时向weight_buffer中装载数据，填满后<code>load_weight_flag = 0</code>。</li>
<li>注意：一次只装载LANE_NUM个卷积核，一共要装载weight_dim4_div_lane次。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Load weight into weight buffer</span></span><br><span class="line"><span class="keyword">if</span>(load_weight_flag==<span class="number">1</span>)&#123;</span><br><span class="line">	weight_ch_vec = weights[out_idx_z*weight_dim1x2x3/VEC_SIZE + output_idx_dim3*weight_dim1x2 + output_idx_dim2*weight_dim1 + output_idx_dim1];</span><br><span class="line">	weight_buffer[output_idx_dim3*weight_dim2*weight_dim1 + output_idx_dim2*weight_dim1 + output_idx_dim1] = weight_ch_vec;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅴ、将数据写入通道-325-382">Ⅴ、将数据写入通道(325-382)</h5>
<ul>
<li>
<p>以下为一个group中，将向量化数据写入channel的过程：</p>
<ul>
<li>
<p>将bias数据写入bias_ch_in(channel_scal型)，然后通过write_channel_intel函数发送到bias_ch通道。</p>
</li>
<li>
<p>将win_buffer数据写入data_vec(lane_data型)，将data_vec复制到LANE_NUM个通道中得到data_ch_vec(channel_vec型)，然后通过write_channel_intel函数发送到data_ch通道。<strong>这一步实现了输入特征图复用</strong>。</p>
</li>
<li>
<p>将weight_buffer数据写入weight_ch_vec(lane_data型)，然后通过write_channel_intel函数发送到weight_ch通道。</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">// Only output data for valid convolution work-items</span></span><br><span class="line"><span class="comment">// In this version, grouping is only performed in row (x) direction</span></span><br><span class="line"><span class="keyword">if</span>(gp_num_x*CONV_GP_SIZE_X+gp_item_idx_x&lt;conv_x)&#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(output_idx_dim1==<span class="number">0</span> &amp;&amp; output_idx_dim2==<span class="number">0</span> &amp;&amp; output_idx_dim3==<span class="number">0</span>)&#123;</span><br><span class="line">		<span class="keyword">if</span>(load_weight_flag==<span class="number">1</span>)&#123;</span><br><span class="line">			bias_ch_in = bias[out_idx_z];</span><br><span class="line">		&#125;</span><br><span class="line">		write_channel_intel(bias_ch, bias_ch_in);</span><br><span class="line">		<span class="comment">//#ifdef DEBUG_MEMRD</span></span><br><span class="line">		<span class="comment">//printf(&quot;work-item x=%d, y=%d, z=%d, channel =0, write bias=%d\n&quot;, output_idx_dim1, output_idx_dim2, output_idx_dim3, bias_ch_in.lane[0]);</span></span><br><span class="line">		<span class="comment">//#endif</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// data</span></span><br><span class="line">	data_vec = win_buffer[flag][output_idx_dim3*win_size_y*win_size_x + output_idx_dim2*win_size_x + (output_idx_dim1+gp_item_idx_x*stride)];</span><br><span class="line">	<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> ll=<span class="number">0</span>; ll&lt;LANE_NUM; ll++)&#123;</span><br><span class="line">		data_ch_vec.lane[ll] = data_vec;</span><br><span class="line">	&#125;</span><br><span class="line">	write_channel_intel(data_ch, data_ch_vec);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="comment">// weight and bias fetcher</span></span><br><span class="line">	weight_ch_vec = weight_buffer[output_idx_dim3*weight_dim2*weight_dim1 + output_idx_dim2*weight_dim1 + output_idx_dim1];</span><br><span class="line">	<span class="comment">//weight_ch_vec = weights[out_idx_z*weight_dim1x2x3/VEC_SIZE + output_idx_dim3*weight_dim1x2 + output_idx_dim2*weight_dim1 + output_idx_dim1];</span></span><br><span class="line">	write_channel_intel(weight_ch, weight_ch_vec);</span><br><span class="line"></span><br><span class="line">	<span class="meta">#<span class="keyword">ifdef</span> DEBUG_MEMRD</span></span><br><span class="line">	<span class="comment">//if(gp_num_x==group_num_x-1 &amp;&amp; gp_num_y==0 &amp;&amp; out_idx_z==0)&#123;</span></span><br><span class="line">		<span class="comment">//printf(&quot;work-item x=%d, y=%d, z=%d, offset=%d, write data in channel 0=%f\n&quot;, output_idx_dim1, output_idx_dim2, output_idx_dim3, data_offset, (float)data_ch_vec.lane[0].data[0]);</span></span><br><span class="line">		<span class="built_in">printf</span>(<span class="string">&quot;work-item x=%d, y=%d, z=%d, write weight in channel 0=%f\n&quot;</span>, output_idx_dim1, output_idx_dim2, output_idx_dim3, (<span class="type">float</span>)weight_ch_vec.lane[<span class="number">0</span>].data[<span class="number">0</span>]);</span><br><span class="line">	<span class="comment">//&#125;</span></span><br><span class="line">	<span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line">	<span class="comment">// used as output loop counters</span></span><br><span class="line">	<span class="keyword">if</span>(((gp_num_x*CONV_GP_SIZE_X+gp_item_idx_x==conv_x<span class="number">-1</span>) || (gp_item_idx_x==CONV_GP_SIZE_X<span class="number">-1</span>)) &amp;&amp; (output_idx_dim3==weight_dim3/VEC_SIZE<span class="number">-1</span>) &amp;&amp; (output_idx_dim2==weight_dim2<span class="number">-1</span>) &amp;&amp; (output_idx_dim1==weight_dim1<span class="number">-1</span>))&#123;</span><br><span class="line">		gp_item_idx_x=<span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>((output_idx_dim3==weight_dim3/VEC_SIZE<span class="number">-1</span>) &amp;&amp; (output_idx_dim2==weight_dim2<span class="number">-1</span>) &amp;&amp; (output_idx_dim1==weight_dim1<span class="number">-1</span>))&#123;</span><br><span class="line">		gp_item_idx_x++;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>((output_idx_dim3==weight_dim3/VEC_SIZE<span class="number">-1</span>) &amp;&amp; (output_idx_dim2==weight_dim2<span class="number">-1</span>) &amp;&amp; (output_idx_dim1==weight_dim1<span class="number">-1</span>))&#123;</span><br><span class="line">		output_idx_dim3 = <span class="number">0</span>;</span><br><span class="line">		load_weight_flag = <span class="number">0</span>;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>((output_idx_dim2==weight_dim2<span class="number">-1</span>)&amp;&amp; (output_idx_dim1==weight_dim1<span class="number">-1</span>))</span><br><span class="line">		output_idx_dim3++;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>((output_idx_dim2==weight_dim2<span class="number">-1</span>) &amp;&amp; (output_idx_dim1==weight_dim1<span class="number">-1</span>))</span><br><span class="line">		output_idx_dim2 = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span> <span class="keyword">if</span>(output_idx_dim1==weight_dim1<span class="number">-1</span>)</span><br><span class="line">		output_idx_dim2++;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(output_idx_dim1==weight_dim1<span class="number">-1</span>)</span><br><span class="line">		output_idx_dim1 = <span class="number">0</span>;</span><br><span class="line">	<span class="keyword">else</span></span><br><span class="line">		output_idx_dim1++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅵ、group计数器-388-427">Ⅵ、group计数器(388-427)</h5>
<ul>
<li>当1个group完成后，更新全局index：out_idx_xyz+1</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">	<span class="keyword">if</span>(item_loop_cnt == item_loop_bound<span class="number">-1</span>)&#123;<span class="comment">//one group is finished</span></span><br><span class="line">		item_loop_cnt = <span class="number">0</span>;</span><br><span class="line">		out_idx_xyz++;</span><br><span class="line">		<span class="comment">// used as virtual group loop counters for winbuf loading operations</span></span><br><span class="line">		<span class="keyword">if</span>((out_idx_z_winbuf==weight_dim4_div_lane<span class="number">-1</span>) &amp;&amp; (gp_num_y_winbuf==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x_winbuf==group_num_x<span class="number">-1</span>))</span><br><span class="line">			out_idx_z_winbuf = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">if</span>((gp_num_y_winbuf==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x_winbuf==group_num_x<span class="number">-1</span>))</span><br><span class="line">			out_idx_z_winbuf++;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>((gp_num_y_winbuf==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x_winbuf==group_num_x<span class="number">-1</span>))</span><br><span class="line">			gp_num_y_winbuf = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">if</span>(gp_num_x_winbuf==group_num_x<span class="number">-1</span>)</span><br><span class="line">			gp_num_y_winbuf++;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>(gp_num_x_winbuf==group_num_x<span class="number">-1</span>)</span><br><span class="line">			gp_num_x_winbuf = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">			gp_num_x_winbuf++;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// used as virtual group loop counters for sending data to the conv kernel</span></span><br><span class="line">		<span class="keyword">if</span>((out_idx_z==weight_dim4_div_lane<span class="number">-1</span>) &amp;&amp; (gp_num_y==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x==group_num_x<span class="number">-1</span>))</span><br><span class="line">			out_idx_z = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">if</span>((gp_num_y==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x==group_num_x<span class="number">-1</span>))&#123;</span><br><span class="line">			out_idx_z++;</span><br><span class="line">			load_weight_flag = <span class="number">1</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>((gp_num_y==group_num_y<span class="number">-1</span>) &amp;&amp; (gp_num_x==group_num_x<span class="number">-1</span>))</span><br><span class="line">			gp_num_y = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span> <span class="keyword">if</span>(gp_num_x==group_num_x<span class="number">-1</span>)</span><br><span class="line">			gp_num_y++;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">if</span>(gp_num_x==group_num_x<span class="number">-1</span>)</span><br><span class="line">			gp_num_x = <span class="number">0</span>;</span><br><span class="line">		<span class="keyword">else</span></span><br><span class="line">			gp_num_x++;</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">else</span>&#123;<span class="comment">//one group is not finished, continued.</span></span><br><span class="line">		item_loop_cnt++;</span><br><span class="line">	&#125;</span><br><span class="line"><span class="comment">//&#125;// end of gp_num_x</span></span><br><span class="line"><span class="comment">//&#125;// end of gp_num_y</span></span><br><span class="line"><span class="comment">//&#125;// end of out_idx_z</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//printf(&quot;Kernel 0 lanched !!!\n&quot;);</span></span><br></pre></td></tr></table></figure>
<h4 id="②-coreConv-kernel">② coreConv kernel</h4>
<h5 id="〇、说明">〇、说明</h5>
<p>硬件结构：</p>
<p><img src="https://cdn.buct-alcp.top/20230915144023.png" alt=""></p>
<p>参数&amp;变量：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">// Params Ports</span><br><span class="line">// 生成输出特征图的循环次数</span><br><span class="line">conv_output_num = conv_x * conv_y * weight_m/LANE_NUM = 55 * 55 * 96/4</span><br><span class="line">// 计算单个向量卷积核的循环次数，LANE_NUM路并行</span><br><span class="line">conv_loop_cnt = weight_w * weight_h * weight_n/VEC_SIZE = 11 * 11 * 8/8</span><br><span class="line">//卷积控制字：该卷积核是否要激活、通过maxpooling层</span><br><span class="line">control = (layer_config[j][conv_relu]&amp;0x01)|(((~layer_config[j][pool_on])&amp;0x01)&lt;&lt;1);</span><br><span class="line">// 精度控制字：需要设计</span><br><span class="line">frac_w = 8</span><br><span class="line">frac_din = 0</span><br><span class="line">frac_dout = -4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	channel_vec mac_data;</span><br><span class="line"> 	channel_vec mac_weight;</span><br><span class="line">	channel_scal bias_ch_out;</span><br><span class="line">	channel_scal conv_ch_in;</span><br><span class="line">	DPTYPE  bias[LANE_NUM];</span><br><span class="line">	MACTYPE conv_out[LANE_NUM];</span><br><span class="line">	MACTYPE lane_accum[LANE_NUM];</span><br><span class="line">	MACTYPE accum_piped[LANE_NUM][PIPE_DEPTH];</span><br><span class="line">	MACTYPE conv_sign_exten[LANE_NUM];</span><br><span class="line">	MACTYPE conv_with_rnd_bit[LANE_NUM];</span><br><span class="line">	MACTYPE conv_sum_bias[LANE_NUM];</span><br><span class="line">	DPTYPE  conv_final[LANE_NUM];</span><br></pre></td></tr></table></figure>
<h5 id="Ⅰ、mac-kernel（乘加算子）">Ⅰ、mac kernel（乘加算子）</h5>
<ul>
<li>输入：深度为VEC_SIZE的weight、data向量。</li>
</ul>
<p><img src="https://cdn.buct-alcp.top/20230906170010.png" alt=""><img src="https://cdn.buct-alcp.top/20230906170010.png" alt=""></p>
<ul>
<li>输出：int32的乘加结果</li>
<li>功能：调用mult_add_fix8bx4 ip核，该ip核支持4路8bit × 8bit乘法并通过加法树求和。</li>
</ul>
<p><img src="https://cdn.buct-alcp.top/20230915145729.png" alt=""></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// parallel MAC units including (VEC_SIZE-1) multipliers</span></span><br><span class="line">MACTYPE <span class="title function_">mac</span><span class="params">(lane_data input, lane_data weights)</span></span><br><span class="line">&#123;</span><br><span class="line">	MACTYPE output = MASK_MULT &amp; CZERO;</span><br><span class="line"></span><br><span class="line">	<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;VEC_SIZE/<span class="number">4</span>; i++)&#123;</span><br><span class="line">		<span class="comment">//output += input.data[i]*weights.data[i];</span></span><br><span class="line">		<span class="comment">// use packed DSP blocks to improve efficiency</span></span><br><span class="line">		output += MASK_MULT &amp; mult_add_fix8bx4(input.data[i*<span class="number">4</span>], weights.data[i*<span class="number">4</span>], input.data[i*<span class="number">4</span>+<span class="number">1</span>], weights.data[i*<span class="number">4</span>+<span class="number">1</span>], input.data[i*<span class="number">4</span>+<span class="number">2</span>], weights.data[i*<span class="number">4</span>+<span class="number">2</span>], input.data[i*<span class="number">4</span>+<span class="number">3</span>], weights.data[i*<span class="number">4</span>+<span class="number">3</span>]);</span><br><span class="line">	&#125;</span><br><span class="line">	<span class="keyword">return</span> output;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h5 id="Ⅱ、代码结构">Ⅱ、代码结构</h5>
<ul>
<li>主循环：这里将conv_loop_cnt循环和output_num循环合并以提高代码效率，<strong>其中conv_loop_cnt循环生成1x1xLANE_NUM个输出像素点，output_num循环输出55x55x96个像素点</strong>。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// conv_loop_cnt iterations generate one 1x1xLANE_NUM output pixels, </span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">int</span> k=<span class="number">0</span>; k&lt;output_num*conv_loop_cnt; k++)&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>当开始一个新的卷积核：填充bias[ll]（ll表示第ll条流水线）；accum_piped[ll][p]清零。</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(conv_inner_cnt == <span class="number">0</span>)&#123;<span class="comment">//starting a new conv kernel</span></span><br><span class="line">	bias_ch_out = read_channel_intel(bias_ch);</span><br><span class="line"></span><br><span class="line">	<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> ll=<span class="number">0</span>; ll&lt;LANE_NUM; ll++)&#123;</span><br><span class="line">		bias[ll] = bias_ch_out.lane[ll]; <span class="comment">// pass to reg, avoid compile error</span></span><br><span class="line">		<span class="comment">// initialize the deep pipelined registers which store PIPE_DEPTH copys of partial results</span></span><br><span class="line">		<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">		<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">int</span> p=<span class="number">0</span>; p&lt;PIPE_DEPTH; p++)&#123;</span><br><span class="line">			accum_piped[ll][p] = MASK_ACCUM &amp; CZERO;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>
<p>LANE_NUM条流水线并行执行mac函数，得到将mac结果与</p>
<p><strong>accum_piped[ll][PIPE_DEPTH-1]</strong>（图中最下面的reg）累加得到<strong>lane_accum[ll]</strong>，它被赋值给<strong>accum_piped[ll][0]</strong>。当下一个点卷积计算完后<strong>accum_piped[ll][0]<strong>下移赋值给</strong>accum_piped[ll][1]</strong>，这就是pipeline加法结构：</p>
</li>
</ul>
<p><img src="https://cdn.buct-alcp.top/20230915153900.png" alt=""></p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// load data and weights for each lane</span></span><br><span class="line">mac_data = read_channel_intel(data_ch);</span><br><span class="line">mac_weight = read_channel_intel(weight_ch);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add results from all lanes</span></span><br><span class="line"><span class="comment">// accumulate with the last copy</span></span><br><span class="line"><span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line"><span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> ll=<span class="number">0</span>; ll&lt;LANE_NUM; ll++)&#123;</span><br><span class="line"></span><br><span class="line">	lane_accum[ll] = (MASK_ACCUM &amp; accum_piped[ll][PIPE_DEPTH<span class="number">-1</span>]) + (MASK_MULT &amp; mac(mac_data.lane[ll], mac_weight.lane[ll]));</span><br><span class="line"></span><br><span class="line">	<span class="comment">// Shift the pipelined registers backwards</span></span><br><span class="line">	<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">	<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">int</span> p=PIPE_DEPTH<span class="number">-1</span>; p&gt;<span class="number">0</span>; p-- )&#123;</span><br><span class="line">		accum_piped[ll][p] = MASK_ACCUM &amp; accum_piped[ll][p<span class="number">-1</span>];</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// update the first copy</span></span><br><span class="line">	accum_piped[ll][<span class="number">0</span>] = MASK_ACCUM &amp; lane_accum[ll];</span><br><span class="line"></span><br><span class="line">	<span class="meta">#<span class="keyword">ifdef</span> DEBUG_CONV</span></span><br><span class="line">	<span class="comment">//if(ll==0 &amp;&amp; k==0)&#123;</span></span><br><span class="line">	<span class="comment">//	printf(&quot;dot_cnt=%d data=%f weight=%f (loop=%d, lane= %d, vec=0)\n&quot;, k, (float)mac_data.lane[ll].data[0], (float)mac_weight.lane[ll].data[0], j, ll);</span></span><br><span class="line">	<span class="comment">//&#125;</span></span><br><span class="line">	<span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>当一个卷积核计算完后，将<strong>accum_piped[ll][PIPE_DEPTH-1] ~ accum_piped[ll][0]<strong>全部相加得到</strong>conv_out[ll]</strong>，这时候的conv_out[ll]是32bit，需要经过精度处理降为8bit。</li>
<li>精度处理：
<ul>
<li>用conv_sign_exten[ll]变量来确定符号位。</li>
<li>将conv_out[ll]变成<strong>9bit</strong>数conv_with_rnd_bit[ll]</li>
<li>处理ovweflow和underflow得到conv_sum_bias[ll]</li>
<li>加上bias[ll]，右移一位得到<strong>conv_final[ll]</strong>，格式为char</li>
</ul>
</li>
<li>ReLU（可选），得到<strong>conv_ch_in.lane[ll]</strong></li>
<li>通过write_channel_intel函数将conv_ch_in发送到conv_ch通道</li>
</ul>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line">		<span class="keyword">if</span>(conv_inner_cnt == conv_loop_cnt<span class="number">-1</span>)&#123;<span class="comment">//One ConvLoop is finished, and 1x1xLANE_NUM conv output is generated. Then the bias and rounding operation is performed.</span></span><br><span class="line">			<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">			<span class="keyword">for</span>(<span class="type">unsigned</span> <span class="type">char</span> ll=<span class="number">0</span>; ll&lt;LANE_NUM; ll++)&#123;</span><br><span class="line">				conv_out[ll] = CZERO;</span><br><span class="line">				<span class="comment">// accumulate all the partial results</span></span><br><span class="line">				<span class="meta">#<span class="keyword">pragma</span> unroll</span></span><br><span class="line">				<span class="keyword">for</span>(<span class="type">unsigned</span> i=<span class="number">0</span>; i&lt;PIPE_DEPTH; i++)&#123;</span><br><span class="line">					conv_out[ll] += accum_piped[ll][i];</span><br><span class="line">				&#125;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// round and truncate the results to the output precision</span></span><br><span class="line">				<span class="comment">// note: ((frac_w+frac_din)-frac_dout)) should be checked by host to be a positive number</span></span><br><span class="line">				<span class="keyword">if</span>(conv_out[ll]&gt;=<span class="number">0</span>)</span><br><span class="line">					conv_sign_exten[ll] = <span class="number">0x00</span>;</span><br><span class="line">				<span class="keyword">else</span></span><br><span class="line">					conv_sign_exten[ll] = ~(<span class="number">0xFFFFFFFF</span>&gt;&gt;(frac_w+frac_din-frac_dout<span class="number">-1</span>)); <span class="comment">// &quot;&gt;&gt;&quot; is logic shift, then perform sign extension manually</span></span><br><span class="line"></span><br><span class="line">				<span class="comment">// First, perform sign extension and the 1st-step rounding before sum with bias</span></span><br><span class="line">				conv_with_rnd_bit[ll] = (conv_sign_exten[ll] | (conv_out[ll]&gt;&gt;(frac_w+frac_din-frac_dout<span class="number">-1</span>))) + <span class="number">0x01</span>;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// Second, deal with Overflow and Underflow cases and the 2nd rounding after sum with bias</span></span><br><span class="line">				<span class="keyword">if</span>(conv_with_rnd_bit[ll]&gt;=<span class="number">256</span>)</span><br><span class="line">					conv_sum_bias[ll] = MASK9B &amp; <span class="number">0xFF</span>; <span class="comment">//=255</span></span><br><span class="line">				<span class="keyword">else</span> <span class="keyword">if</span>(conv_with_rnd_bit[ll]&lt;<span class="number">-256</span>)</span><br><span class="line">					conv_sum_bias[ll] = MASK9B &amp; <span class="number">0x100</span>; <span class="comment">//=-256</span></span><br><span class="line">				<span class="keyword">else</span></span><br><span class="line">					<span class="comment">// clear 1st-step rounding bit by using MASK9B</span></span><br><span class="line">					<span class="comment">// then sum with bias and perform 2nd-step rounding</span></span><br><span class="line">					<span class="comment">// note: (frac_w-frac_dout-1) should be checked by host to be a positive number</span></span><br><span class="line">					conv_sum_bias[ll] = (MASK9B &amp; conv_with_rnd_bit[ll])+(bias[ll]&gt;&gt;(frac_w-frac_dout<span class="number">-1</span>))+<span class="number">0x01</span>;</span><br><span class="line"></span><br><span class="line">				<span class="comment">// final truncation</span></span><br><span class="line">				conv_final[ll] = MASK8B &amp; (conv_sum_bias[ll]&gt;&gt;<span class="number">0x01</span>);  <span class="comment">// remove the last rounding bit</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> RESNET</span></span><br><span class="line">				conv_ch_in.lane[ll]= conv_final[ll];</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="comment">//BatchNorm</span></span><br><span class="line">			<span class="keyword">if</span>(contol==<span class="number">0</span>)</span><br><span class="line">				write_channel_intel(conv_ch, conv_ch_in);</span><br><span class="line">			<span class="keyword">else</span><span class="comment">//for fc layer no bn,Write</span></span><br><span class="line">				write_channel_intel(bypass_bn_ch, conv_ch_in);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">				<span class="comment">// Relu operation</span></span><br><span class="line">				<span class="keyword">if</span>((contol&amp;<span class="number">0x01</span>)==<span class="number">0x01</span>)&#123;</span><br><span class="line">					<span class="keyword">if</span>((conv_final[ll]&amp;MASKSIGN)==MASKSIGN) <span class="comment">// MSB is sign bit</span></span><br><span class="line">						conv_ch_in.lane[ll] = <span class="number">0</span>;</span><br><span class="line">					<span class="keyword">else</span></span><br><span class="line">						conv_ch_in.lane[ll] = conv_final[ll];</span><br><span class="line">				&#125;</span><br><span class="line">				<span class="keyword">else</span></span><br><span class="line">					conv_ch_in.lane[ll] = conv_final[ll];</span><br><span class="line"></span><br><span class="line">				<span class="meta">#<span class="keyword">ifdef</span> DEBUG_CONV</span></span><br><span class="line">				<span class="keyword">if</span>(ll==<span class="number">0</span> &amp;&amp; k==<span class="number">0</span>)</span><br><span class="line">					<span class="built_in">printf</span>(<span class="string">&quot;dot_cnt=%d sum=%f rnd=%f sum_bias=%f final=%f (bias=%f)\n\n&quot;</span>, k, (<span class="type">float</span>)conv_out[ll], (<span class="type">float</span>)conv_with_rnd_bit[ll], (<span class="type">float</span>)conv_sum_bias[ll], (<span class="type">float</span>)conv_final[ll], (<span class="type">float</span>)bias[ll]);</span><br><span class="line">				<span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">			&#125;</span><br><span class="line">			write_channel_intel(conv_ch, conv_ch_in);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">			conv_inner_cnt = <span class="number">0</span>;</span><br><span class="line">		&#125;<span class="comment">//Bias and rounding operation is finished.</span></span><br><span class="line">		<span class="keyword">else</span>&#123;<span class="comment">//One conv kernel is not finished, continued.</span></span><br><span class="line">			conv_inner_cnt++;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;<span class="comment">// end of output loop</span></span><br><span class="line">	<span class="comment">//printf(&quot;Kernel coreConv lanched !!!\n&quot;);</span></span><br></pre></td></tr></table></figure>
<h5 id="Ⅲ、关于精度控制字">Ⅲ、关于精度控制字</h5>
<p>由于我们每一层的权重、输入、输出都是8bit，范围是[-128,127]。<strong>对于不同范围的权重、输入、输出需要有对应的精度控制字来进行合理的8bit量化：frac_w、frac_din、frac_dout</strong></p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">frac_w</th>
<th style="text-align:center">frac_din</th>
<th style="text-align:center">frac_dout</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">值</td>
<td style="text-align:center">8</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-4</td>
</tr>
<tr>
<td style="text-align:center">精度</td>
<td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mn>8</mn></mrow></msup></mrow><annotation encoding="application/x-tex">2^{-8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></td>
<td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">2^0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></td>
<td style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">2^4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></td>
</tr>
<tr>
<td style="text-align:center">原始值范围</td>
<td style="text-align:center">[-0.5,0.5)</td>
<td style="text-align:center">[-128,127]</td>
<td style="text-align:center">[-2048,2047]</td>
</tr>
<tr>
<td style="text-align:center">相当于原始值</td>
<td style="text-align:center">×<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>8</mn></msup></mrow><annotation encoding="application/x-tex">2^{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></td>
<td style="text-align:center">×<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>0</mn></msup></mrow><annotation encoding="application/x-tex">2^{0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span></span></span></span></td>
<td style="text-align:center">×<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup></mrow><annotation encoding="application/x-tex">2^{-4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span></td>
</tr>
</tbody>
</table>
<p><strong>这段代码是如何推导的：</strong><code>conv_with_rnd_bit[ll] = (conv_sign_exten[ll] | (conv_out[ll]&gt;&gt;(frac_w+frac_din-frac_dout-1))) + 0x01;</code></p>
<p>计算卷积：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi></mrow><annotation encoding="application/x-tex">conv\_out = \sum\ data × weight</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9251em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">conv\_final = \sum\ data × weight + bias</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ina</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span></span></span></span></p>
<p>按照原始值来计算应该这样写：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><msup><mn>2</mn><mn>0</mn></msup><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup></mrow><annotation encoding="application/x-tex">conv\_out × 2^{-4} = \sum\ data × 2^{0} × weight × 2^{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9251em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><msup><mn>2</mn><mn>0</mn></msup><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup><mo>×</mo><msup><mn>2</mn><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">conv\_out  = \sum\ data × 2^{0} × weight × 2^{8} × 2^{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9251em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>+</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>n</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">conv\_out  = \sum\ data × weight × 2^{frac\_w + frac\_din - frac\_dout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.9251em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">o</span><span class="mord mathnormal">u</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">in</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>n</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>i</mi><mi>t</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>+</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>n</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">conv\_with\_rnd\_bit  = \sum\ data × weight × 2^{frac\_w + frac\_din - frac\_dout-1} + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">bi</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9324em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">in</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></p>
<p>式中的“+1”为四舍五入。</p>
<p><strong>这段代码是如何推导的：</strong><code>conv_sum_bias[ll] = (MASK9B &amp; conv_with_rnd_bit[ll])+(bias[ll]&gt;&gt;(frac_w-frac_dout-1))+0x01;</code> ，其中MASK9B = 0x1FE</p>
<p>计算卷积：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi></mrow><annotation encoding="application/x-tex">conv\_final = \sum\ data × weight + bias</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ina</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span></span></span></span></p>
<p>按照原始值来计算应该这样写：</p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mo>×</mo><msup><mn>2</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><msup><mn>2</mn><mn>0</mn></msup><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup></mrow><annotation encoding="application/x-tex">conv\_final × 2^{-4} = \sum\ data × 2^{0} × weight × 2^{8} + bias × 2^{8}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ina</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><msup><mn>2</mn><mn>0</mn></msup><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup><mo>×</mo><msup><mn>2</mn><mn>4</mn></msup><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo>×</mo><msup><mn>2</mn><mn>8</mn></msup><mo>×</mo><msup><mn>2</mn><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">conv\_final  = \sum\ data × 2^{0} × weight × 2^{8} × 2^{4} + bias × 2^{8} × 2^{4}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ina</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">0</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8974em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">8</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">4</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>f</mi><mi>i</mi><mi>n</mi><mi>a</mi><mi>l</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>+</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>n</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msup><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><msup><mi>s</mi><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">conv\_final  = \sum\ data × weight × 2^{frac\_w + frac\_din - frac\_dout} + bias^{frac\_w - frac\_dout}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">ina</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9324em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">in</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord mathnormal">bia</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo>=</mo><mo>∑</mo><mtext> </mtext><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi><mo>×</mo><mi>w</mi><mi>e</mi><mi>i</mi><mi>g</mi><mi>h</mi><mi>t</mi><mo>×</mo><msup><mn>2</mn><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>+</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>i</mi><mi>n</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><msup><mi>s</mi><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">conv\_sum\_bias  = \sum\ data × weight × 2^{frac\_w + frac\_din - frac\_dout-1} + bias^{frac\_w - frac\_dout - 1} + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">e</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">h</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9324em;vertical-align:-0.0833em;"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">in</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9324em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">bia</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>s</mi><mi>u</mi><mi>m</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>i</mi><mi>a</mi><mi>s</mi><mo>=</mo><mrow><mi>M</mi><mi>A</mi><mi>S</mi><mi>K</mi><mn>9</mn><mi>B</mi></mrow><mtext> </mtext><mi mathvariant="normal">&amp;</mi><mtext> </mtext><mi>c</mi><mi>o</mi><mi>n</mi><mi>v</mi><mi mathvariant="normal">_</mi><mi>w</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>r</mi><mi>n</mi><mi>d</mi><mi mathvariant="normal">_</mi><mi>b</mi><mi>i</mi><mi>t</mi><mo>+</mo><mi>b</mi><mi>i</mi><mi>a</mi><msup><mi>s</mi><mrow><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>w</mi><mo>−</mo><mi>f</mi><mi>r</mi><mi>a</mi><mi>c</mi><mi mathvariant="normal">_</mi><mi>d</mi><mi>o</mi><mi>u</mi><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msup><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">conv\_sum\_bias  = {MASK9B}\  \&amp;\ conv\_with\_rnd\_bit + bias^{frac\_w - frac\_dout - 1} + 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord mathnormal">m</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">bia</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0044em;vertical-align:-0.31em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord">9</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span><span class="mspace"> </span><span class="mord">&amp;</span><span class="mspace"> </span><span class="mord mathnormal">co</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">n</span><span class="mord mathnormal">d</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">bi</span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.9324em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">bia</span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight" style="margin-right:0.02691em;">w</span><span class="mbin mtight">−</span><span class="mord mathnormal mtight" style="margin-right:0.10764em;">f</span><span class="mord mathnormal mtight" style="margin-right:0.02778em;">r</span><span class="mord mathnormal mtight">a</span><span class="mord mathnormal mtight">c</span><span class="mord mtight" style="margin-right:0.02778em;">_</span><span class="mord mathnormal mtight">d</span><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://ANG404me.github.io">ANG404</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ang404me.github.io/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/">https://ang404me.github.io/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ANG404me.github.io" target="_blank">ANG404's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/SoC-FPGA/">SoC FPGA</a><a class="post-meta__tags" href="/tags/de10-nano/">de10_nano</a><a class="post-meta__tags" href="/tags/OpenCL/">OpenCL</a><a class="post-meta__tags" href="/tags/PipeCNN/">PipeCNN</a></div><div class="post_share"><div class="social-share" data-image="https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&amp;w=3870&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/03/%E3%80%90SoC-FPGA%E3%80%91ALINX-AXU4EVB%E5%BC%80%E5%8F%91%E6%9D%BF%E7%A7%BB%E6%A4%8DPYNQ/" title="【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ"><img class="cover" src="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?q=80&amp;w=2670&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ</div></div></a></div><div class="next-post pull-right"><a href="/2023/09/12/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/" title="【SoC FPGA】5.OpenCL程序设计流程"><img class="cover" src="https://images.unsplash.com/photo-1721340143289-94be4f77cda4?q=80&amp;w=2832&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【SoC FPGA】5.OpenCL程序设计流程</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/09/12/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/" title="【SoC FPGA】5.OpenCL程序设计流程"><img class="cover" src="https://images.unsplash.com/photo-1721340143289-94be4f77cda4?q=80&w=2832&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-12</div><div class="title">【SoC FPGA】5.OpenCL程序设计流程</div></div></a></div><div><a href="/2023/09/05/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80/" title="【SoC FPGA】3.OpenCL异构计算基础"><img class="cover" src="https://images.unsplash.com/photo-1720451815682-3353b81a6633?q=80&w=3604&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-05</div><div class="title">【SoC FPGA】3.OpenCL异构计算基础</div></div></a></div><div><a href="/2023/09/09/%E3%80%90SoC%20FPGA%E3%80%91%E9%9D%A2%E5%90%91Intel%20FPGA%20%E7%9A%84%20OpenCL%2018.1%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/" title="【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建"><img class="cover" src="https://plus.unsplash.com/premium_photo-1721405381040-10cbc42ee4a5?q=80&w=3870&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-09</div><div class="title">【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建</div></div></a></div><div><a href="/2023/08/30/%E3%80%90SoC%20FPGA%E3%80%91GDB%20Server%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95%E3%80%81GDB%20ARM%20%E4%BA%A4%E5%8F%89%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="【SoC FPGA】2.GDB Server远程调试、GDB ARM 交叉编译环境搭建"><img class="cover" src="https://plus.unsplash.com/premium_photo-1663946899728-39b7b401535e?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1335&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-30</div><div class="title">【SoC FPGA】2.GDB Server远程调试、GDB ARM 交叉编译环境搭建</div></div></a></div><div><a href="/2023/08/27/%E3%80%90SoC%20FPGA%E3%80%91%E5%AE%BF%E4%B8%BB%E6%9C%BA%E3%80%81%E8%99%9A%E6%8B%9F%E6%9C%BA%E3%80%81%E5%BC%80%E5%8F%91%E6%9D%BF%EF%BC%88de10_nano%EF%BC%89%E4%B9%8B%E9%97%B4%E7%9A%84%E9%80%9A%E4%BF%A1/" title="【SoC FPGA】1.宿主机、虚拟机、开发板（de10_nano）之间的通信"><img class="cover" src="https://images.unsplash.com/photo-1517181875630-f72350452109?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=2670&q=80" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-27</div><div class="title">【SoC FPGA】1.宿主机、虚拟机、开发板（de10_nano）之间的通信</div></div></a></div><div><a href="/2023/11/03/%E3%80%90SoC-FPGA%E3%80%91ALINX-AXU4EVB%E5%BC%80%E5%8F%91%E6%9D%BF%E7%A7%BB%E6%A4%8DPYNQ/" title="【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ"><img class="cover" src="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?q=80&w=2670&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-03</div><div class="title">【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DibbupDOTKvQMfAaYkjlvq4nR5Zkxd8ebYiauKfmGDGzYHbP5xhEG0FXkCoT3KaC8xe7WguiaKLA3AzNuYGe2V8ibg/132" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">ANG404</div><div class="author-info__description"></div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">14</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">24</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">5</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/ANG404me"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/ANG404me" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">QQ:1453897678</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">PipeCNN代码精读</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81OpenCL%E5%9F%BA%E7%A1%80"><span class="toc-text">一、OpenCL基础</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1%E3%80%81host%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%E6%AD%A5%E9%AA%A4"><span class="toc-text">1.1、host程序编程步骤</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81host%E4%BB%A3%E7%A0%81"><span class="toc-text">二、host代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1%E3%80%81%E4%BB%A3%E7%A0%81%E7%9B%AE%E5%BD%95"><span class="toc-text">2.1、代码目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2%E3%80%81main-cpp%E5%A4%B4%E6%96%87%E4%BB%B6%E3%80%81%E5%AE%9A%E4%B9%89"><span class="toc-text">2.2、main.cpp头文件、定义</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3%E3%80%81main-cpp%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%9A%84%E7%BB%93%E6%9E%84%EF%BC%88%E4%B8%8Elayer-config-h%E6%96%87%E4%BB%B6%E7%9B%B8%E5%85%B3%EF%BC%89"><span class="toc-text">2.3、main.cpp配置文件的结构（与layer_config.h文件相关）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4%E3%80%81main-cpp%E5%A3%B0%E6%98%8E%E5%8F%98%E9%87%8F%E4%B8%8E%E5%87%BD%E6%95%B0"><span class="toc-text">2.4、main.cpp声明变量与函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5%E3%80%81-main-cpp%E4%B8%BB%E5%87%BD%E6%95%B0%E9%83%A8%E5%88%86"><span class="toc-text">2.5、*main.cpp主函数部分</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0-%E8%BF%9E%E6%8E%A5%E5%B9%B3%E5%8F%B0"><span class="toc-text">① 连接平台</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1-%E6%89%93%E5%8D%B0%E5%8F%AF%E7%94%A8%E7%9A%84OpenCL%E5%B9%B3%E5%8F%B0"><span class="toc-text">② 打印可用的OpenCL平台</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A2-%E6%89%93%E5%8D%B0%E8%AE%BE%E5%A4%87%E5%90%8D%E7%A7%B0"><span class="toc-text">③ 打印设备名称</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A3-%E5%88%9B%E5%BB%BA%E4%B8%8A%E4%B8%8B%E6%96%87"><span class="toc-text">④ 创建上下文</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A4-%E5%88%9B%E5%BB%BA%E7%A8%8B%E5%BA%8F%E5%AF%B9%E8%B1%A1"><span class="toc-text">⑤ 创建程序对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A5-%E5%88%9B%E5%BB%BA%E4%B8%80%E7%BB%84%E7%BC%93%E5%86%B2%E5%8C%BA%E5%92%8C%E5%AF%B9%E8%B1%A1"><span class="toc-text">⑥ 创建一组缓冲区和对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A6-prepare-%E5%87%BD%E6%95%B0"><span class="toc-text">⑦ prepare()函数</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%87%E3%80%81ptr%E5%8F%82%E6%95%B0"><span class="toc-text">〇、ptr参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A0%E3%80%81%E5%8F%82%E6%95%B0%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E5%AE%89%E5%85%A8%E6%A3%80%E6%9F%A5"><span class="toc-text">Ⅰ、参数初始化与安全检查</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A1%E3%80%81%E4%B8%BAweights-dat%E5%92%8Cimage-dat%E5%88%86%E9%85%8D%E7%A9%BA%E9%97%B4"><span class="toc-text">Ⅱ、为weights.dat和image.dat分配空间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A2%E3%80%81%E8%BE%93%E5%85%A5%E5%9B%BE%E5%83%8F%E9%80%9A%E9%81%93padding"><span class="toc-text">Ⅲ、输入图像通道padding</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A3%E3%80%81%E4%B8%BAdata-init%E5%88%86%E9%85%8D%E7%A9%BA%E9%97%B4"><span class="toc-text">Ⅳ、为data_init分配空间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A4%E3%80%81%E4%B8%BA%E8%BE%93%E5%87%BA%E5%8F%98%E9%87%8F%E5%88%86%E9%85%8D%E7%A9%BA%E9%97%B4"><span class="toc-text">Ⅴ、为输出变量分配空间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A5%E3%80%81%E4%B8%BA%E6%AF%8F%E5%B1%82%E7%9A%84weights%E5%92%8Cbias%E5%88%86%E9%85%8D%E7%A9%BA%E9%97%B4"><span class="toc-text">Ⅵ、为每层的weights和bias分配空间</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A6%E3%80%81%E5%86%99%E5%85%A5%E6%95%B0%E6%8D%AE"><span class="toc-text">Ⅶ、写入数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A7%E3%80%81-reorderWeights-%E3%80%81reorderBias-%E5%87%BD%E6%95%B0"><span class="toc-text">Ⅷ、*reorderWeights()、reorderBias()函数</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#reorderWeights"><span class="toc-text">reorderWeights()</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#reorderBias"><span class="toc-text">reorderBias()</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A7-%E5%88%9B%E5%BB%BA%E5%91%BD%E4%BB%A4%E9%98%9F%E5%88%97%E3%80%81%E5%86%85%E6%A0%B8"><span class="toc-text">⑧ 创建命令队列、内核</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A8-%E5%88%9B%E5%BB%BAFPGA%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-text">⑨ 创建FPGA缓冲区</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A0%E3%80%81%E5%88%9B%E5%BB%BAweights%E3%80%81bias%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-text">Ⅰ、创建weights、bias缓冲区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A1%E3%80%81%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-text">Ⅱ、创建数据缓冲区</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A2%E3%80%81%E5%88%9B%E5%BB%BA%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E7%BC%93%E5%86%B2%E5%8C%BA"><span class="toc-text">Ⅲ、创建全连接层缓冲区</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A9-%E6%89%A7%E8%A1%8C%E5%86%85%E6%A0%B8"><span class="toc-text">⑩ 执行内核</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A0%E3%80%81loadImageToBuffer-%E5%87%BD%E6%95%B0"><span class="toc-text">Ⅰ、loadImageToBuffer()函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A1%E3%80%81-%E7%BD%91%E7%BB%9C%E7%9A%84%E6%89%A7%E8%A1%8C%E6%AD%A5%E9%AA%A4%E8%AF%B4%E6%98%8E"><span class="toc-text">Ⅱ、*网络的执行步骤说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A2%E3%80%81%E8%AE%A1%E7%AE%97%E5%B9%B6%E9%85%8D%E7%BD%AEMemRd%E8%BE%93%E5%85%A5%E5%8F%82%E6%95%B0"><span class="toc-text">Ⅲ、计算并配置MemRd输入参数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A3%E3%80%81%E9%85%8D%E7%BD%AEMemRd%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E6%9D%A5%E6%BA%90"><span class="toc-text">Ⅳ、配置MemRd输入数据来源</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A4%E3%80%81%E9%85%8D%E7%BD%AECONV-%E8%BE%93%E5%85%A5%E5%8F%82%E6%95%B0-883-907"><span class="toc-text">Ⅴ、配置CONV 输入参数(883-907)</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81kernel%E4%BB%A3%E7%A0%81"><span class="toc-text">三、kernel代码</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%E8%AF%B4%E6%98%8E"><span class="toc-text">3.1 数据类型说明</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%BB%91%E5%8A%A8%E7%AA%97%E4%B8%8E%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B"><span class="toc-text">3.2 滑动窗与卷积过程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0-%E6%BB%91%E5%8A%A8%E7%AA%97%E7%BB%93%E6%9E%84%E7%A4%BA%E6%84%8F%E5%9B%BE"><span class="toc-text">① 滑动窗结构示意图</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1-group%E4%B8%8Eitem"><span class="toc-text">② group与item</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A2-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8D%B7%E7%A7%AF%E8%BF%87%E7%A8%8B"><span class="toc-text">③ 滑动窗卷积过程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-conv-pipe-cl%E4%BB%A3%E7%A0%81"><span class="toc-text">3.3 conv_pipe.cl代码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A0-memRead-kernel"><span class="toc-text">① memRead kernel</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%87%E3%80%81%E5%8F%82%E6%95%B0%E8%AF%B4%E6%98%8E"><span class="toc-text">〇、参数说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A0%E3%80%81%E5%88%9D%E5%A7%8B%E5%8C%96%E7%AC%AC%E4%B8%80%E4%B8%AAwin-buffer-181-205"><span class="toc-text">Ⅰ、初始化第一个win_buffer(181-205)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A1%E3%80%81%E8%AE%A1%E7%AE%97%E5%8D%B7%E7%A7%AF%E5%8F%82%E6%95%B0-210-241"><span class="toc-text">Ⅱ、计算卷积参数(210-241)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A2%E3%80%81%E8%A3%85%E8%BD%BD%E4%B8%80%E4%B8%AA%E6%96%B0%E7%9A%84group-250-315"><span class="toc-text">Ⅲ、装载一个新的group(250-315)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A3%E3%80%81%E8%A3%85%E8%BD%BDweight-buffer-318-321"><span class="toc-text">Ⅳ、装载weight_buffer(318-321)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A4%E3%80%81%E5%B0%86%E6%95%B0%E6%8D%AE%E5%86%99%E5%85%A5%E9%80%9A%E9%81%93-325-382"><span class="toc-text">Ⅴ、将数据写入通道(325-382)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A5%E3%80%81group%E8%AE%A1%E6%95%B0%E5%99%A8-388-427"><span class="toc-text">Ⅵ、group计数器(388-427)</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E2%91%A1-coreConv-kernel"><span class="toc-text">② coreConv kernel</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E3%80%87%E3%80%81%E8%AF%B4%E6%98%8E"><span class="toc-text">〇、说明</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A0%E3%80%81mac-kernel%EF%BC%88%E4%B9%98%E5%8A%A0%E7%AE%97%E5%AD%90%EF%BC%89"><span class="toc-text">Ⅰ、mac kernel（乘加算子）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A1%E3%80%81%E4%BB%A3%E7%A0%81%E7%BB%93%E6%9E%84"><span class="toc-text">Ⅱ、代码结构</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E2%85%A2%E3%80%81%E5%85%B3%E4%BA%8E%E7%B2%BE%E5%BA%A6%E6%8E%A7%E5%88%B6%E5%AD%97"><span class="toc-text">Ⅲ、关于精度控制字</span></a></li></ol></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/11/03/%E3%80%90SoC-FPGA%E3%80%91ALINX-AXU4EVB%E5%BC%80%E5%8F%91%E6%9D%BF%E7%A7%BB%E6%A4%8DPYNQ/" title="【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ"><img src="https://images.unsplash.com/photo-1550751827-4bd374c3f58b?q=80&amp;w=2670&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ"/></a><div class="content"><a class="title" href="/2023/11/03/%E3%80%90SoC-FPGA%E3%80%91ALINX-AXU4EVB%E5%BC%80%E5%8F%91%E6%9D%BF%E7%A7%BB%E6%A4%8DPYNQ/" title="【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ">【SoC FPGA】7.ALINX AXU4EVB开发板移植PYNQ</a><time datetime="2023-11-03T06:41:08.000Z" title="发表于 2023-11-03 14:41:08">2023-11-03</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/" title="【SoC FPGA】6.PipeCNN代码精读"><img src="https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&amp;w=3870&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【SoC FPGA】6.PipeCNN代码精读"/></a><div class="content"><a class="title" href="/2023/09/15/%E3%80%90SoC-FPGA%E3%80%91PipeCNN%E4%BB%A3%E7%A0%81%E7%B2%BE%E8%AF%BB/" title="【SoC FPGA】6.PipeCNN代码精读">【SoC FPGA】6.PipeCNN代码精读</a><time datetime="2023-09-15T06:41:08.000Z" title="发表于 2023-09-15 14:41:08">2023-09-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/12/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/" title="【SoC FPGA】5.OpenCL程序设计流程"><img src="https://images.unsplash.com/photo-1721340143289-94be4f77cda4?q=80&amp;w=2832&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【SoC FPGA】5.OpenCL程序设计流程"/></a><div class="content"><a class="title" href="/2023/09/12/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%B5%81%E7%A8%8B/" title="【SoC FPGA】5.OpenCL程序设计流程">【SoC FPGA】5.OpenCL程序设计流程</a><time datetime="2023-09-12T06:41:08.000Z" title="发表于 2023-09-12 14:41:08">2023-09-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/09/%E3%80%90SoC%20FPGA%E3%80%91%E9%9D%A2%E5%90%91Intel%20FPGA%20%E7%9A%84%20OpenCL%2018.1%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/" title="【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建"><img src="https://plus.unsplash.com/premium_photo-1721405381040-10cbc42ee4a5?q=80&amp;w=3870&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建"/></a><div class="content"><a class="title" href="/2023/09/09/%E3%80%90SoC%20FPGA%E3%80%91%E9%9D%A2%E5%90%91Intel%20FPGA%20%E7%9A%84%20OpenCL%2018.1%E8%BF%90%E8%A1%8C%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/" title="【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建">【SoC FPGA】4.面向Intel FPGA 的 OpenCL 18.1运行平台搭建</a><time datetime="2023-09-09T06:41:08.000Z" title="发表于 2023-09-09 14:41:08">2023-09-09</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/09/05/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80/" title="【SoC FPGA】3.OpenCL异构计算基础"><img src="https://images.unsplash.com/photo-1720451815682-3353b81a6633?q=80&amp;w=3604&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【SoC FPGA】3.OpenCL异构计算基础"/></a><div class="content"><a class="title" href="/2023/09/05/%E3%80%90SoC%20FPGA%E3%80%91OpenCL%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E5%9F%BA%E7%A1%80/" title="【SoC FPGA】3.OpenCL异构计算基础">【SoC FPGA】3.OpenCL异构计算基础</a><time datetime="2023-09-05T06:41:08.000Z" title="发表于 2023-09-05 14:41:08">2023-09-05</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://plus.unsplash.com/premium_photo-1721926057308-2aa7ce470776?q=80&amp;w=3870&amp;auto=format&amp;fit=crop&amp;ixlib=rb-4.0.3&amp;ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By ANG404</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-info"><div class="algolia-stats"></div><div class="algolia-poweredBy"></div></div></div></div></div><div id="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/algoliasearch/dist/algoliasearch-lite.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script></div></body></html>